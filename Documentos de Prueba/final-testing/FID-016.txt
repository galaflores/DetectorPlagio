The pursuit of biologically inspired cognitive architectures (BICA) has driven significant advancements in artificial intelligence (AI) and artificial general intelligence (AGI). However, most existing BICA models lack a critical aspect of human intelligence: emotions and feelings. The development and implementation of an emotion-integrated cognitive architecture that mimics human emotional processing within a computational framework is explored in this research. Our proposed architecture, Emotion-Integrated Cognitive Architecture (EICA), is inspired by the latest findings in cognitive psychology, neurobiology, neuroscience and affective computing. EICA aims to integrate emotional processing into the core of the AI system, enabling robust, flexible, and adaptable AI agents that can respond to complex and dynamic environments with human-like emotional intelligence. The EICA model leverages advances in brain imaging and recording techniques to draw insights from the neural basis of emotions in humans. The architecture incorporates emotion-generating, recognition, and regulation mechanisms, allowing AI agents to perceive, interpret, and respond to emotions in themselves and others. The concept of EICA, including its modular structure and interaction with other cognitive components is presented by us. Case studies showcasing EICA's successful implementation in various AI applications, such as virtual assistants and adaptive robotics are provided by us. This research represents a significant step towards achieving the BICA Challenge by advancing the computational replication of human emotional intelligence. By integrating emotions and feelings into AI systems, we move closer to realizing the full potential of bi-directional understanding between artificial and biological intelligences.