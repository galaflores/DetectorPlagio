Facial Expression Recognition (FER) is utilized in various fields, such as education, gaming, robotics, healthcare, and others. Facial expression techniques, for instance, an interactive robot with Artificial Intelligence, recognize human faces, detect the emotions of the person it is conversing with, and then use these emotions to choose appropriate answers. One use case for face emotion detection is playing music based on the user’s mood. To do this, we can analyze the user’s facial expression to deduce their feelings. As a result, new emotion models require more investigation as existing one’s struggle to correctly measure music’s connection with facial emotion. In this paper, we implement this kind of job using Convolution Neural Network (CNN) based deep learning approach. Deep learning can more effectively analyze unstructured data, movies, and other forms of media than machine learning. In our research, we have created a real-time system that can recognize human faces, assess human emotions, and even recommend music to users. The OAHEGA and FER-2013 datasets were utilized for experimental study. We created and trained two emotion recognition models using various combinations of these datasets. The proposed model’s accuracy is 73.02%. Using our CNN model, we can predict six emotions: anger, fear, joy, neutral, sadness, and surprise. The proposed system can be utilized in different places where real-time facial recognition plays an important role.