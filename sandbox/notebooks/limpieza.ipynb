{
 "cells": [
  {
   "cell_type": "code",
   "id": "a160284983477fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.784630Z",
     "start_time": "2024-05-02T06:03:56.333341Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import difflib\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.util import ngrams\n",
    "import gensim.downloader as api\n",
    "import re\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "nltk.download('punkt')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() #lemmatizer algorithm\n",
    "lancStemmer = LancasterStemmer()  # stemming algorithm Lancaster"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sergiogonzalez/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sergiogonzalez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 388
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocesamiento de texto",
   "id": "9d86e79d49756202"
  },
  {
   "cell_type": "code",
   "id": "cabc55928702054c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.787729Z",
     "start_time": "2024-05-02T06:03:56.785714Z"
    }
   },
   "source": [
    "def remove_stopwords(text):\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    palabras = [palabra.lower() for palabra in re.findall(r'\\w+', text.lower())]\n",
    "    text_lista = []\n",
    "    for palabra in palabras:\n",
    "        if palabra not in stopwords:\n",
    "            text_lista.append(palabra)\n",
    "    nuevo_texto = ' '.join(text_lista)\n",
    "    return nuevo_texto\n"
   ],
   "outputs": [],
   "execution_count": 389
  },
  {
   "cell_type": "code",
   "id": "42d531059485839a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.789867Z",
     "start_time": "2024-05-02T06:03:56.788149Z"
    }
   },
   "source": [
    "def get_lemmatizer(text):\n",
    "    palabras = remove_stopwords(text)\n",
    "    palabras = palabras.split()\n",
    "    text_lista = []\n",
    "    for palabra in palabras:\n",
    "        nueva = lemmatizer.lemmatize(palabra)\n",
    "        text_lista.append(nueva)\n",
    "    nuevo_texto = ' '.join(text_lista)\n",
    "    return nuevo_texto"
   ],
   "outputs": [],
   "execution_count": 390
  },
  {
   "cell_type": "code",
   "id": "e3366f7a6073761d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.792297Z",
     "start_time": "2024-05-02T06:03:56.790807Z"
    }
   },
   "source": [
    "def get_stemmer(text):\n",
    "    palabras = remove_stopwords(text)\n",
    "    palabras = palabras.split()\n",
    "    text_lista = []\n",
    "    for palabra in palabras:\n",
    "        nueva = lancStemmer.stem(palabra)\n",
    "        text_lista.append(nueva)\n",
    "    nuevo_texto = ' '.join(text_lista)\n",
    "    return nuevo_texto"
   ],
   "outputs": [],
   "execution_count": 391
  },
  {
   "cell_type": "code",
   "id": "fe7413594574936f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.795042Z",
     "start_time": "2024-05-02T06:03:56.792729Z"
    }
   },
   "source": [
    "def get_grams(text, ngram, method):\n",
    "    result = []\n",
    "\n",
    "    if method == 'lemmatize':\n",
    "        text = get_lemmatizer(text)\n",
    "        if ngram == 0:  # Si ngram es 0, se retorna el texto completo sin ngramas\n",
    "            text = nltk.sent_tokenize(text)\n",
    "            text = ' '.join(text)\n",
    "            return text\n",
    "\n",
    "        else:\n",
    "            text = text.split()\n",
    "            grams = ngrams(text, ngram)\n",
    "            for ng in grams:\n",
    "                result.append(' '.join(ng))\n",
    "    elif method == 'stemmer':\n",
    "        text = get_stemmer(text)\n",
    "        if ngram == 0:  # Si ngram es 0, se retorna el texto completo sin ngramas\n",
    "            text = nltk.sent_tokenize(text)\n",
    "            text = ' '.join(text)\n",
    "            return text\n",
    "\n",
    "        else:\n",
    "            text = text.split()\n",
    "            grams = ngrams(text, ngram)\n",
    "            for ng in grams:\n",
    "                result.append(' '.join(ng))\n",
    "    else:\n",
    "        raise ValueError('Method not found')\n",
    "\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 392
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.796828Z",
     "start_time": "2024-05-02T06:03:56.795430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def token_sentence(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    filtered_sentences = []\n",
    "    for sentence in sentences:\n",
    "        filtered_words = get_lemmatizer(sentence)\n",
    "        filtered_sentences.append(filtered_words)\n",
    "\n",
    "    return filtered_sentences"
   ],
   "id": "3e783c5598be2bd",
   "outputs": [],
   "execution_count": 393
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Deteccion de plagio",
   "id": "d538115095025094"
  },
  {
   "cell_type": "code",
   "id": "aac47f6a85ab8cbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.799687Z",
     "start_time": "2024-05-02T06:03:56.797426Z"
    }
   },
   "source": [
    "def preprocess_docs(folder_path, ngram, method):\n",
    "    tagged_documents = []\n",
    "    for fileid in os.listdir(folder_path):\n",
    "        if fileid.endswith(\".txt\"):\n",
    "            filepath = os.path.join(folder_path, fileid)\n",
    "            \n",
    "            with open(filepath, 'r', encoding='latin1', errors='ignore') as file:\n",
    "                text = file.read()\n",
    "                grams = get_grams(text, ngram, method)\n",
    "                # Ensure words are split into a list of strings and then converted to tuple\n",
    "                words = tuple(word.split() for word in grams)\n",
    "                # Flatten the list of lists into a single list of strings\n",
    "                words = [word for sublist in words for word in sublist]\n",
    "                tagged_documents.append(TaggedDocument(words=words, tags=[fileid]))\n",
    "\n",
    "    return tagged_documents"
   ],
   "outputs": [],
   "execution_count": 394
  },
  {
   "cell_type": "code",
   "id": "f6c0ca04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.802623Z",
     "start_time": "2024-05-02T06:03:56.800245Z"
    }
   },
   "source": [
    "def preprocess_docs_with_sentence(folder_path, ngram, method):\n",
    "    tagged_documents = []\n",
    "    for fileid in os.listdir(folder_path):\n",
    "        if fileid.endswith(\".txt\"):\n",
    "            filepath = os.path.join(folder_path, fileid)\n",
    "            \n",
    "            with open(filepath, 'r', encoding='latin1', errors='ignore') as file:\n",
    "                text = file.read()\n",
    "                sentences = nltk.sent_tokenize(text)  # Tokenizar el texto en oraciones\n",
    "                document_sentences = []  # Lista para almacenar las oraciones del documento\n",
    "\n",
    "                for sentence in sentences:\n",
    "                    grams = get_grams(sentence, ngram, method)\n",
    "                    # Separar las palabras y agregarlas a la lista de oraciones del documento\n",
    "                    words = [word for gram in grams for word in gram.split()]\n",
    "                    document_sentences.append(words)\n",
    "                \n",
    "                tagged_documents.append(TaggedDocument(words=document_sentences, tags=[fileid]))\n",
    "\n",
    "    return tagged_documents"
   ],
   "outputs": [],
   "execution_count": 395
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Deteccion de Tipo de plagio",
   "id": "f9b65cf6965f9b04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.804692Z",
     "start_time": "2024-05-02T06:03:56.803128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def detect_sentence_disorder(original_sentences, plagio_sentences):\n",
    "    #cantidad de oraciones es diferente, hay desorden\n",
    "    if len(original_sentences) != len(plagio_sentences):\n",
    "        return True\n",
    "    \n",
    "    #verifica si el orden de las oraciones es diferente\n",
    "    for original, plagio in zip(original_sentences, plagio_sentences):\n",
    "        if original != plagio:\n",
    "            return True\n",
    "        \n",
    "    return False"
   ],
   "id": "8e0d2eeb",
   "outputs": [],
   "execution_count": 396
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.808279Z",
     "start_time": "2024-05-02T06:03:56.806422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk import pos_tag\n",
    "def detect_time_change(og_text, plagio_text):\n",
    "    original_verbs = [word for word, pos in nltk.pos_tag(nltk.word_tokenize(og_text)) if pos.startswith('VB')]\n",
    "    suspicious_verbs = [word for word, pos in nltk.pos_tag(nltk.word_tokenize(plagio_text)) if pos.startswith('VB')]\n",
    "\n",
    "    # Si la lista de verbos es diferente, hay un cambio de tiempo\n",
    "    if set(original_verbs) != set(suspicious_verbs):\n",
    "        return True\n",
    "            \n",
    "    return False"
   ],
   "id": "9938dba7",
   "outputs": [],
   "execution_count": 397
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.810441Z",
     "start_time": "2024-05-02T06:03:56.808700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def detect_inserted_sentences(og_text, plagio_text):\n",
    "    og_sentences = token_sentence(og_text)\n",
    "    plagio_sentences = token_sentence(plagio_text)\n",
    "    \n",
    "    #si el plagio tiene mas oraciones que el original, hay oraciones insertadas\n",
    "    if len(plagio_sentences) > len(og_sentences):\n",
    "        return True\n",
    "    \n",
    "    #si el plagio tiene menos oraciones que el original, hay oraciones eliminadas\n",
    "    if len(plagio_sentences) < len(og_sentences):\n",
    "        return True\n",
    "    \n",
    "    #verifica si el orden de las oraciones es diferente\n",
    "    if detect_sentence_disorder(og_sentences, plagio_sentences):\n",
    "        return True\n",
    "    \n",
    "    return False"
   ],
   "id": "48c4394f",
   "outputs": [],
   "execution_count": 398
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.812685Z",
     "start_time": "2024-05-02T06:03:56.810961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def detect_voice_change(og_text, plagio_text):\n",
    "    original_verbs = [word for word, pos in nltk.pos_tag(nltk.word_tokenize(og_text)) if pos.startswith('VB')]\n",
    "    suspicious_verbs = [word for word, pos in nltk.pos_tag(nltk.word_tokenize(plagio_text)) if pos.startswith('VB')]\n",
    "\n",
    "    # Si la lista de verbos es diferente, hay un cambio de voz\n",
    "    if set(original_verbs) != set(suspicious_verbs):\n",
    "        return True\n",
    "            \n",
    "    return False"
   ],
   "id": "34eabd47",
   "outputs": [],
   "execution_count": 399
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.814698Z",
     "start_time": "2024-05-02T06:03:56.813151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def detect_paraphrasing(og_text, plagio_text, model):\n",
    "    similarity_threshold = 0.95  # Umbral de similitud para considerar el parafraseo\n",
    "\n",
    "    similarity = calculate_similarity_doc2vec(og_text, plagio_text, model)\n",
    "    if similarity >= similarity_threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ],
   "id": "e083d009",
   "outputs": [],
   "execution_count": 400
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generacion de modelo, entrenamiento y calculo de similitud",
   "id": "2f5e8b1c2894b197"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.816688Z",
     "start_time": "2024-05-02T06:03:56.815105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_doc2vec(tagged_documents):\n",
    "    model = Doc2Vec(vector_size=100, window=5, min_count=1, epochs=200,\n",
    "                    dm=0)  # dm=0 for distributed bag of words (DBOW) mode\n",
    "    model.build_vocab(tagged_documents)\n",
    "    model.train(tagged_documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    return model"
   ],
   "id": "5fa60796b8922db4",
   "outputs": [],
   "execution_count": 401
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.818516Z",
     "start_time": "2024-05-02T06:03:56.817116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_similarity_doc2vec(doc1, doc2, model):\n",
    "    vec1 = model.infer_vector(doc1.words)\n",
    "    vec2 = model.infer_vector(doc2.words)\n",
    "    similarity = model.dv.similarity(doc1.tags[0], doc2.tags[0])\n",
    "    return similarity"
   ],
   "id": "701a181f33632fd9",
   "outputs": [],
   "execution_count": 402
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# APLICACION DE MODELO",
   "id": "fd33183036c31d5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Preprocesamiento de documentos originales y plagiados",
   "id": "f9d549ac2476a9a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:56.944637Z",
     "start_time": "2024-05-02T06:03:56.818938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Obtener n-gramas preprocesados\n",
    "folder_path = \"../../textos_plagiados\"  # Ruta de la carpeta con los textos plagiados)\n",
    "folder_path_og = \"../../docs_originales\"  # Ruta de la carpeta con los textos originales\n",
    "\n",
    "\n",
    "# Preprocessing original and plagiarized documents\n",
    "tagged_originals = preprocess_docs(folder_path_og, 1, 'lemmatize')\n",
    "tagged_plagiarized = preprocess_docs(folder_path, 1, 'lemmatize')\n",
    "\n",
    "# Preprocessing original and plagiarized documents with sentences\n",
    "tagged_originals_with_sentence = preprocess_docs_with_sentence(folder_path_og, 1, 'lemmatize')\n",
    "tagged_plagiarized_with_sentence = preprocess_docs_with_sentence(folder_path, 1, 'lemmatize')"
   ],
   "id": "ea3ff018",
   "outputs": [],
   "execution_count": 403
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###  Entrenamiento del modelo Doc2Vec ",
   "id": "b8345b1f2624df1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:03:58.394180Z",
     "start_time": "2024-05-02T06:03:56.945327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sin sentence\n",
    "model = train_doc2vec(tagged_originals + tagged_plagiarized)"
   ],
   "id": "4ed9d5f29397de45",
   "outputs": [],
   "execution_count": 404
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:04:28.452943Z",
     "start_time": "2024-05-02T06:04:01.896346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# List to store similarity results\n",
    "similarity_results = []\n",
    "#plagiarism_type = '' \n",
    "\n",
    "# Iterating over each plagiarized text\n",
    "for plagio_doc in tagged_plagiarized:\n",
    "    max_similarity = 0\n",
    "    most_similar = ''\n",
    "    most_similar_doc = ''\n",
    "\n",
    "    # Comparing with each original document\n",
    "    for original_doc in tagged_originals:\n",
    "        similarity = calculate_similarity_doc2vec(plagio_doc, original_doc, model)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            most_similar = original_doc.tags[0]\n",
    "            most_similar_doc = original_doc.words\n",
    "\n",
    "    similarity_results.append([plagio_doc.tags[0], most_similar, max_similarity, most_similar_doc])\n",
    "\n",
    "        \n",
    "\n",
    "# Sorting results by similarity in descending order\n",
    "similarity_results.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Printing results\n",
    "for result in similarity_results:\n",
    "    plagio_title, original_title, similarity_score, original_doc = result\n",
    "    print(f\"Similarity between '{plagio_title}' and '{original_title}': {similarity_score * 100:.2f}%\")\n"
   ],
   "id": "70848c546b0d322e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'FID-04.txt' and 'org-045.txt': 99.70%\n",
      "Similarity between 'FID-03.txt' and 'org-016.txt': 99.67%\n",
      "Similarity between 'FID-05.txt' and 'org-085.txt': 96.04%\n",
      "Similarity between 'FID-09.txt' and 'org-109.txt': 93.44%\n",
      "Similarity between 'FID-08.txt' and 'org-079.txt': 92.37%\n",
      "Similarity between 'FID-06.txt' and 'org-043.txt': 92.01%\n",
      "Similarity between 'FID-07.txt' and 'org-041.txt': 88.62%\n",
      "Similarity between 'FID-02.txt' and 'org-104.txt': 87.72%\n",
      "Similarity between 'FID-10.txt' and 'org-007.txt': 87.01%\n",
      "Similarity between 'FID-01.txt' and 'org-076.txt': 77.66%\n"
     ]
    }
   ],
   "execution_count": 406
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Entrenamiento del modelo Doc2Vec con oraciones",
   "id": "f074da7bcc563b49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T06:11:38.163122Z",
     "start_time": "2024-05-02T06:11:38.135974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# con sentence\n",
    "model_with_sentence = train_doc2vec(tagged_originals_with_sentence + tagged_plagiarized_with_sentence)"
   ],
   "id": "c582b2cc1a9a2d35",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'TaggedDocument'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[411], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# con sentence\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m model_with_sentence \u001B[38;5;241m=\u001B[39m train_doc2vec(tagged_originals_with_sentence \u001B[38;5;241m+\u001B[39m tagged_plagiarized_with_sentence)\n",
      "Cell \u001B[0;32mIn[410], line 34\u001B[0m, in \u001B[0;36mtrain_doc2vec\u001B[0;34m(original_documents)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_doc2vec\u001B[39m(original_documents):\n\u001B[0;32m---> 34\u001B[0m     tagged_data \u001B[38;5;241m=\u001B[39m [TaggedDocument(words\u001B[38;5;241m=\u001B[39mpreprocess(doc)\u001B[38;5;241m.\u001B[39msplit(), tags\u001B[38;5;241m=\u001B[39m[\u001B[38;5;28mstr\u001B[39m(i)]) \u001B[38;5;28;01mfor\u001B[39;00m i, doc \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(original_documents)]\n\u001B[1;32m     35\u001B[0m     model \u001B[38;5;241m=\u001B[39m Doc2Vec(vector_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m, window\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, min_count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n\u001B[1;32m     36\u001B[0m     model\u001B[38;5;241m.\u001B[39mbuild_vocab(tagged_data)\n",
      "Cell \u001B[0;32mIn[410], line 34\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_doc2vec\u001B[39m(original_documents):\n\u001B[0;32m---> 34\u001B[0m     tagged_data \u001B[38;5;241m=\u001B[39m [TaggedDocument(words\u001B[38;5;241m=\u001B[39mpreprocess(doc)\u001B[38;5;241m.\u001B[39msplit(), tags\u001B[38;5;241m=\u001B[39m[\u001B[38;5;28mstr\u001B[39m(i)]) \u001B[38;5;28;01mfor\u001B[39;00m i, doc \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(original_documents)]\n\u001B[1;32m     35\u001B[0m     model \u001B[38;5;241m=\u001B[39m Doc2Vec(vector_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m, window\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, min_count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n\u001B[1;32m     36\u001B[0m     model\u001B[38;5;241m.\u001B[39mbuild_vocab(tagged_data)\n",
      "Cell \u001B[0;32mIn[410], line 14\u001B[0m, in \u001B[0;36mpreprocess\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpreprocess\u001B[39m(text):\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;66;03m# Remove special characters and digits\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m     text \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[^a-zA-Z\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms]\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, text)\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;66;03m# Convert to lowercase\u001B[39;00m\n\u001B[1;32m     17\u001B[0m     text \u001B[38;5;241m=\u001B[39m text\u001B[38;5;241m.\u001B[39mlower()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/re/__init__.py:185\u001B[0m, in \u001B[0;36msub\u001B[0;34m(pattern, repl, string, count, flags)\u001B[0m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msub\u001B[39m(pattern, repl, string, count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, flags\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m    179\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001B[39;00m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001B[39;00m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001B[39;00m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001B[39;00m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;124;03m    a callable, it's passed the Match object and must return\u001B[39;00m\n\u001B[1;32m    184\u001B[0m \u001B[38;5;124;03m    a replacement string to be used.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 185\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _compile(pattern, flags)\u001B[38;5;241m.\u001B[39msub(repl, string, count)\n",
      "\u001B[0;31mTypeError\u001B[0m: expected string or bytes-like object, got 'TaggedDocument'"
     ]
    }
   ],
   "execution_count": 411
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_plagiarism_type(doc1, doc2, model):\n",
    "    vec1 = model.infer_vector(doc1.words)\n",
    "    vec2 = model.infer_vector(doc2.words)\n",
    "\n",
    "    plagiarism_type = []\n",
    "    for plagio_doc in tagged_plagiarized:\n",
    "        max_similarity = 0\n",
    "        most_similar = ''\n",
    "        most_similar_doc = ''\n",
    "\n",
    "        # Comparing with each original document\n",
    "        for original_doc in tagged_originals:\n",
    "            similarity = calculate_similarity_doc2vec(plagio_doc, original_doc, model)\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                most_similar = original_doc.tags[0]\n",
    "                most_similar_doc = original_doc.words\n",
    "\n",
    "    plagiarism_type.append([plagio_doc.tags[0], most_similar, max_similarity, most_similar_doc])"
   ],
   "id": "58c2ebd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### TESTING OTROS",
   "id": "91e85e2b770988ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "original_folder = \"../../docs_originales\"\n",
    "plagiarized_folder = \"../../textos_plagiados\""
   ],
   "id": "dde913aa4a7e9855"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T07:43:55.407659Z",
     "start_time": "2024-05-02T07:43:55.399379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Classify plagiarism type\n",
    "def classify_plagiarism_type(original_doc, plagiarized_doc):\n",
    "    # Preprocesa los documentos\n",
    "    original_processed = preprocess(original_doc)\n",
    "    plagiarized_processed = preprocess(plagiarized_doc)\n",
    "\n",
    "    # Tokeniza los documentos en frases\n",
    "    original_sentences = nltk.sent_tokenize(original_processed)\n",
    "    plagiarized_sentences = nltk.sent_tokenize(plagiarized_processed)\n",
    "\n",
    "    # Comprueba si el plagio involucra insertar o reemplazar frases\n",
    "    if len(original_sentences) < len(plagiarized_sentences):\n",
    "        return \"Insertar o reemplazar frases\"\n",
    "\n",
    "    # Comprueba si el plagio involucra desordenar las frases\n",
    "    if set(original_sentences) != set(plagiarized_sentences):\n",
    "        return \"Desordenar las frases\"\n",
    "\n",
    "    # Comprueba si el plagio involucra cambio de tiempo\n",
    "    # Implementa tu lógica aquí...\n",
    "\n",
    "    # Comprueba si el plagio involucra cambio de voz\n",
    "    # Implementa tu lógica aquí...\n",
    "\n",
    "    # Comprueba si el plagio involucra parafraseo\n",
    "    if original_processed != plagiarized_processed:\n",
    "        return \"Parafraseo\"\n",
    "\n",
    "    # Si no se identifica ningún tipo específico de plagio, se devuelve un mensaje genérico\n",
    "    return \"Tipo de plagio no identificado\"\n",
    "\n",
    "# Ejemplo de uso:\n",
    "original_doc = \"El cambio climático es un problema global.\"\n",
    "plagiarized_doc = \"El cambio climático se convierte en una preocupación a nivel mundial.\"\n",
    "\n",
    "plagiarism_type = classify_plagiarism_type(original_doc, plagiarized_doc)\n",
    "print(\"Tipo de plagio:\", plagiarism_type)\n"
   ],
   "id": "1752fc490b2491dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de plagio: Desordenar las frases\n"
     ]
    }
   ],
   "execution_count": 416
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:18:27.389798Z",
     "start_time": "2024-05-02T08:18:27.372390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def detectar_tipo_plagio(original, plagio):\n",
    "    tokens_original = nltk.word_tokenize(original)\n",
    "    tokens_plagio = nltk.word_tokenize(plagio)\n",
    "    similitud = SequenceMatcher(None, tokens_original, tokens_plagio).ratio()\n",
    "    if similitud == 1.0:\n",
    "        return \"Parafraseo\"\n",
    "    elif similitud >= 0.8:\n",
    "        return \"Insertar o reemplazar frases\"\n",
    "    elif similitud >= 0.6:\n",
    "        return \"Cambio de tiempo\"\n",
    "    elif similitud >= 0.4:\n",
    "        return \"Desordenar las frases\"\n",
    "    else:\n",
    "        return \"Cambio de voz\"\n",
    "\n",
    "# Recorrer cada par de documentos en similarity_results\n",
    "for result in similarity_results:\n",
    "    plagio_title, original_title, similarity_score, original_doc = result\n",
    "    original_doc_text = ' '.join([word for word in original_doc])\n",
    "    plagiarized_doc_text = [doc.words for doc in tagged_plagiarized if doc.tags[0] == plagio_title][0]\n",
    "    plagiarized_doc_text = ' '.join([word for word in plagiarized_doc_text])\n",
    "\n",
    "    # print(f\"Titulo: {plagio_title}\")\n",
    "    print(f\"Similitud entre '{plagio_title}' y '{original_title}': {similarity_score * 100:.2f}%\")\n",
    "    tipo_plagio = detectar_tipo_plagio(original_doc_text, plagiarized_doc_text)\n",
    "    print(\"Tipo de plagio:\", tipo_plagio)\n",
    "    # print(\"Coincidencias para el plagio:\")\n",
    "    print(\"----------------------------\")\n",
    "    # print(f\"Cadena original: (Longitud: {len(original_doc_text)})\")\n",
    "    # print(f\"Cadena plagiada:  (Longitud: {len(plagiarized_doc_text)})\")\n",
    "    # print()\n"
   ],
   "id": "825f68e7f113f2bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud entre 'FID-04.txt' y 'org-045.txt': 99.67%\n",
      "Tipo de plagio: Desordenar las frases\n",
      "----------------------------\n",
      "Similitud entre 'FID-03.txt' y 'org-016.txt': 99.61%\n",
      "Tipo de plagio: Cambio de tiempo\n",
      "----------------------------\n",
      "Similitud entre 'FID-05.txt' y 'org-085.txt': 96.28%\n",
      "Tipo de plagio: Insertar o reemplazar frases\n",
      "----------------------------\n",
      "Similitud entre 'FID-09.txt' y 'org-109.txt': 94.06%\n",
      "Tipo de plagio: Cambio de tiempo\n",
      "----------------------------\n",
      "Similitud entre 'FID-08.txt' y 'org-079.txt': 92.26%\n",
      "Tipo de plagio: Cambio de tiempo\n",
      "----------------------------\n",
      "Similitud entre 'FID-06.txt' y 'org-043.txt': 91.83%\n",
      "Tipo de plagio: Insertar o reemplazar frases\n",
      "----------------------------\n",
      "Similitud entre 'FID-07.txt' y 'org-041.txt': 88.74%\n",
      "Tipo de plagio: Cambio de tiempo\n",
      "----------------------------\n",
      "Similitud entre 'FID-02.txt' y 'org-104.txt': 87.64%\n",
      "Tipo de plagio: Cambio de tiempo\n",
      "----------------------------\n",
      "Similitud entre 'FID-10.txt' y 'org-007.txt': 86.77%\n",
      "Tipo de plagio: Cambio de tiempo\n",
      "----------------------------\n",
      "Similitud entre 'FID-01.txt' y 'org-076.txt': 77.38%\n",
      "Tipo de plagio: Cambio de tiempo\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sergiogonzalez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 441
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T08:16:40.603095Z",
     "start_time": "2024-05-02T08:16:40.581691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def detectar_tipo_plagio(original, plagio):\n",
    "    tokens_original = nltk.word_tokenize(original)\n",
    "    tokens_plagio = nltk.word_tokenize(plagio)\n",
    "    similitud = SequenceMatcher(None, tokens_original, tokens_plagio).ratio()\n",
    "    \n",
    "    # Obtener tokens de n-gramas\n",
    "    ngrams_original = set(nltk.ngrams(tokens_original, 2))\n",
    "    ngrams_plagio = set(nltk.ngrams(tokens_plagio, 2))\n",
    "    \n",
    "    print(\"ngrams originales: \", ngrams_original)\n",
    "    print(\"ngrams plagio: \", ngrams_plagio)\n",
    "    # Verificar la cantidad de n-gramas compartidos\n",
    "    shared_ngrams = len(ngrams_original.intersection(ngrams_plagio))\n",
    "    total_ngrams = len(ngrams_original.union(ngrams_plagio))\n",
    "    ratio_ngrams = shared_ngrams / total_ngrams\n",
    "    \n",
    "    # Mejorar la detección de tipo de plagio utilizando más criterios\n",
    "    if similitud == 1.0:\n",
    "        return \"Parafraseo\"\n",
    "    elif ratio_ngrams > 0.8:\n",
    "        return \"Parafraseo o reordenamiento de frases\"\n",
    "    elif ratio_ngrams > 0.5:\n",
    "        return \"Reordenamiento de frases\"\n",
    "    elif similitud > 0.8:\n",
    "        return \"Parafraseo o inserción de frases\"\n",
    "    elif similitud > 0.6:\n",
    "        return \"Inserción de frases\"\n",
    "    elif similitud > 0.4:\n",
    "        return \"Cambio de tiempo o desorden de frases\"\n",
    "    else:\n",
    "        return \"Cambio de voz\"\n",
    "\n",
    "# Recorrer cada par de documentos en similarity_results\n",
    "for result in similarity_results:\n",
    "    plagio_title, original_title, similarity_score, original_doc = result\n",
    "    original_doc_text = ' '.join([word for word in original_doc])\n",
    "    plagiarized_doc_text = [doc.words for doc in tagged_plagiarized if doc.tags[0] == plagio_title][0]\n",
    "    plagiarized_doc_text = ' '.join([word for word in plagiarized_doc_text])\n",
    "\n",
    "    print(f\"Titulo: {plagio_title}\")\n",
    "    print(f\"Similitud entre '{plagio_title}' y '{original_title}': {similarity_score * 100:.2f}%\")\n",
    "    tipo_plagio = detectar_tipo_plagio(original_doc_text, plagiarized_doc_text)\n",
    "    print(\"Tipo de plagio:\", tipo_plagio)\n",
    "    print(\"Coincidencias para el plagio:\")\n",
    "    print(\"----------------------------\")\n",
    "    print(f\"Cadena original: (Longitud: {len(original_doc_text)})\")\n",
    "    print(f\"Cadena plagiada:  (Longitud: {len(plagiarized_doc_text)})\")\n",
    "    print()\n"
   ],
   "id": "eaf3c8531a7108d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titulo: FID-04.txt\n",
      "Similitud entre 'FID-04.txt' y 'org-045.txt': 99.67%\n",
      "ngrams originales:  {('agent', 'need'), ('two', 'state'), ('definition', 'controlled'), ('condition', 'assessing'), ('engage', 'user'), ('empathy', 'time'), ('formal', 'definition'), ('system', 'recognize'), ('well', 'chatbots'), ('art', 'tool'), ('empathy', 'interactionsâ'), ('system', 'assessing'), ('order', 'understand'), ('interactive', 'agent'), ('interactionsâ', 'interactive'), ('chatbots', 'replika'), ('applying', 'tool'), ('review', 'qualitative'), ('change', 'intervention'), ('area', 'health'), ('owl', 'may'), ('recent', 'approach'), ('approach', 'empathy'), ('definition', 'implemented'), ('consensus', 'formal'), ('empathy', 'interactive'), ('finding', 'suggest'), ('agent', 'evaluating'), ('study', 'applying'), ('variety', 'definition'), ('intervention', 'increased'), ('time', 'definition'), ('empathy', 'two'), ('implemented', 'web'), ('understand', 'empathic'), ('behavior', 'change'), ('ontology', 'language'), ('comfort', 'behavior'), ('software', 'agent'), ('performance', 'intelligent'), ('coaching', 'comfort'), ('definition', 'based'), ('based', 'systematic'), ('used', 'area'), ('assessing', 'empathic'), ('user', 'interpersonal'), ('art', 'health'), ('g', 'coaching'), ('formal', 'definitionâ'), ('tool', 'enabling'), ('need', 'understanding'), ('health', 'well'), ('user', 'study'), ('agentsâ', 'empathic'), ('recognize', 'empathy'), ('progressively', 'used'), ('literature', 'discus'), ('capability', 'current'), ('ontologyâ', 'empathy'), ('application', 'agent'), ('literature', 'review'), ('e', 'g'), ('potential', 'formal'), ('empathic', 'capability'), ('qualitative', 'analysis'), ('conversation', 'e'), ('increased', 'need'), ('empathy', 'consensus'), ('may', 'serve'), ('precise', 'notion'), ('analysis', 'recent'), ('assessing', 'empathy'), ('perception', 'empathy'), ('suggest', 'definition'), ('evaluating', 'empathic'), ('uncover', 'explain'), ('explain', 'trend'), ('agent', 'health'), ('automated', 'tool'), ('present', 'potential'), ('empathy', 'developed'), ('intelligent', 'system'), ('interpersonal', 'conversation'), ('web', 'ontology'), ('serve', 'automated'), ('replika', 'wysa'), ('tool', 'order'), ('empathy', 'literature'), ('discus', 'variety'), ('interactive', 'software'), ('need', 'precise'), ('state', 'art'), ('definitionâ', 'ontologyâ'), ('well', 'formal'), ('definition', 'empathy'), ('wysa', 'finding'), ('systematic', 'literature'), ('language', 'owl'), ('enabling', 'system'), ('trend', 'changing'), ('tool', 'assessing'), ('capability', 'interlocutor'), ('necessary', 'condition'), ('changing', 'perception'), ('well', 'application'), ('understanding', 'agentsâ'), ('notion', 'empathy'), ('capture', 'necessary'), ('current', 'state'), ('empathic', 'performance'), ('agent', 'engage'), ('chatbots', 'progressively'), ('definition', 'capture'), ('agent', 'uncover'), ('capability', 'interactive'), ('controlled', 'user'), ('agent', 'chatbots'), ('developed', 'present')}\n",
      "ngrams plagio:  {('agent', 'need'), ('two', 'state'), ('definition', 'controlled'), ('condition', 'assessing'), ('engage', 'user'), ('empathy', 'time'), ('formal', 'definition'), ('system', 'recognize'), ('well', 'chatbots'), ('art', 'tool'), ('interlocutor', 'current'), ('empathy', 'interactionsâ'), ('system', 'assessing'), ('order', 'understand'), ('interactive', 'agent'), ('interactionsâ', 'interactive'), ('chatbots', 'replika'), ('applying', 'tool'), ('developed', 'order'), ('review', 'qualitative'), ('change', 'intervention'), ('area', 'health'), ('owl', 'may'), ('recent', 'approach'), ('approach', 'empathy'), ('definition', 'implemented'), ('definition', 'application'), ('empathy', 'interactive'), ('agent', 'evaluating'), ('finding', 'suggest'), ('consensus', 'formal'), ('study', 'applying'), ('variety', 'definition'), ('intervention', 'increased'), ('implemented', 'web'), ('empathy', 'two'), ('ontology', 'language'), ('understand', 'empathic'), ('behavior', 'change'), ('comfort', 'behavior'), ('software', 'agent'), ('coaching', 'comfort'), ('assessing', 'empathic'), ('used', 'area'), ('based', 'systematic'), ('user', 'interpersonal'), ('art', 'health'), ('g', 'coaching'), ('formal', 'definitionâ'), ('tool', 'enabling'), ('need', 'understanding'), ('health', 'well'), ('user', 'study'), ('agentsâ', 'empathic'), ('recognize', 'empathy'), ('progressively', 'used'), ('literature', 'discus'), ('ontologyâ', 'empathy'), ('literature', 'review'), ('application', 'agent'), ('e', 'g'), ('potential', 'formal'), ('empathic', 'capability'), ('qualitative', 'analysis'), ('conversation', 'e'), ('increased', 'need'), ('empathy', 'consensus'), ('tool', 'present'), ('may', 'serve'), ('analysis', 'recent'), ('assessing', 'empathy'), ('precise', 'notion'), ('perception', 'empathy'), ('suggest', 'definition'), ('evaluating', 'empathic'), ('uncover', 'explain'), ('explain', 'trend'), ('automated', 'tool'), ('agent', 'health'), ('present', 'potential'), ('empathy', 'developed'), ('intelligent', 'system'), ('interpersonal', 'conversation'), ('web', 'ontology'), ('serve', 'automated'), ('replika', 'wysa'), ('empathy', 'literature'), ('discus', 'variety'), ('interactive', 'software'), ('state', 'art'), ('need', 'precise'), ('definitionâ', 'ontologyâ'), ('well', 'formal'), ('definition', 'empathy'), ('wysa', 'finding'), ('systematic', 'literature'), ('language', 'owl'), ('enabling', 'system'), ('trend', 'changing'), ('tool', 'assessing'), ('capability', 'interlocutor'), ('necessary', 'condition'), ('changing', 'perception'), ('understanding', 'agentsâ'), ('notion', 'empathy'), ('capture', 'necessary'), ('current', 'state'), ('empathic', 'performance'), ('definition', 'capture'), ('chatbots', 'progressively'), ('agent', 'engage'), ('agent', 'uncover'), ('controlled', 'user'), ('capability', 'interactive'), ('well', 'definition'), ('agent', 'chatbots'), ('time', 'based'), ('performance', 'intelligent')}\n",
      "Tipo de plagio: Parafraseo o reordenamiento de frases\n",
      "Coincidencias para el plagio:\n",
      "----------------------------\n",
      "Cadena original: (Longitud: 1098)\n",
      "Cadena plagiada:  (Longitud: 1098)\n",
      "\n",
      "Titulo: FID-03.txt\n",
      "Similitud entre 'FID-03.txt' y 'org-016.txt': 99.61%\n",
      "ngrams originales:  {('platform', 'embedded'), ('x', 'much'), ('intelligent', 'robot'), ('accounted', '81'), ('5', '90'), ('system', 'recognition'), ('machine', 'svm'), ('also', 'face'), ('actual', 'application'), ('control', 'smart'), ('security', 'data'), ('good', 'response'), ('embedded', 'hardware'), ('remarkable', 'result'), ('system', 'accounted'), ('system', 'x'), ('certain', 'extent'), ('development', 'seriously'), ('5', '10'), ('computer', 'interaction'), ('problem', 'low'), ('design', 'support'), ('evaluation', 'respectively'), ('combined', 'embedded'), ('interaction', 'etc'), ('algorithm', 'realize'), ('higher', 'system'), ('svm', 'algorithm'), ('81', '96'), ('seriously', 'hampered'), ('designed', 'ep'), ('technology', 'ep'), ('however', 'ai'), ('result', 'showed'), ('detection', 'function'), ('evaluation', 'system'), ('system', 'v'), ('received', 'good'), ('90', 'positive'), ('unstable', 'system'), ('positive', 'relationship'), ('low', 'overall'), ('etc', 'present'), ('ai', 'industrial'), ('present', 'visual'), ('16', '5'), ('ai', 'technology'), ('respectively', 'however'), ('network', 'security'), ('development', 'efficiency'), ('test', 'result'), ('v', 'based'), ('function', 'test'), ('recognition', 'efficiency'), ('vision', 'system'), ('19', '4'), ('based', 'ai'), ('realize', 'intelligent'), ('certain', 'requirement'), ('requirement', 'improve'), ('interaction', 'target'), ('positive', 'evaluation'), ('x', '16'), ('performance', 'paper'), ('application', 'requirement'), ('hardware', 'design'), ('efficiency', 'certain'), ('accounted', '19'), ('embedded', 'system'), ('96', 'proportion'), ('field', 'received'), ('student', 'expert'), ('showed', 'condition'), ('4', 'negative'), ('however', 'positive'), ('application', 'artificial'), ('computer', 'performance'), ('robot', 'interaction'), ('system', 'indicated'), ('data', 'analysis'), ('hampered', 'problem'), ('visual', 'platform'), ('expert', '83'), ('system', 'performance'), ('proportion', 'positive'), ('improve', 'system'), ('platform', 'combined'), ('target', 'detection'), ('result', 'practical'), ('technology', 'certain'), ('83', '5'), ('evaluation', 'accounted'), ('relationship', 'ai'), ('analysis', 'human'), ('ep', 'vision'), ('smart', 'home'), ('condition', 'student'), ('meet', 'actual'), ('x', 'meet'), ('technology', 'platform'), ('present', 'application'), ('paper', 'designed'), ('human', 'computer'), ('ep', 'v'), ('requirement', 'computer'), ('achieved', 'remarkable'), ('performance', 'also'), ('showed', 'positive'), ('response', 'however'), ('industrial', 'control'), ('overall', 'development'), ('extent', 'showed'), ('intelligence', 'ai'), ('home', 'field'), ('negative', 'evaluation'), ('face', 'problem'), ('much', 'higher'), ('application', 'development'), ('support', 'vector'), ('artificial', 'intelligence'), ('indicated', 'system'), ('practical', 'application'), ('problem', 'network'), ('efficiency', 'unstable'), ('system', 'achieved'), ('vector', 'machine'), ('10', 'negative')}\n",
      "ngrams plagio:  {('platform', 'embedded'), ('x', 'much'), ('intelligent', 'robot'), ('accounted', '81'), ('5', '90'), ('system', 'recognition'), ('machine', 'svm'), ('also', 'face'), ('actual', 'application'), ('control', 'smart'), ('respectively', 'paper'), ('security', 'data'), ('good', 'response'), ('embedded', 'hardware'), ('remarkable', 'result'), ('system', 'accounted'), ('system', 'x'), ('certain', 'extent'), ('development', 'seriously'), ('5', '10'), ('computer', 'interaction'), ('problem', 'low'), ('design', 'support'), ('evaluation', 'respectively'), ('combined', 'embedded'), ('interaction', 'etc'), ('algorithm', 'realize'), ('higher', 'system'), ('svm', 'algorithm'), ('81', '96'), ('seriously', 'hampered'), ('designed', 'ep'), ('technology', 'ep'), ('however', 'ai'), ('result', 'showed'), ('detection', 'function'), ('evaluation', 'system'), ('system', 'v'), ('received', 'good'), ('90', 'positive'), ('unstable', 'system'), ('positive', 'relationship'), ('low', 'overall'), ('etc', 'present'), ('ai', 'industrial'), ('present', 'visual'), ('16', '5'), ('ai', 'technology'), ('network', 'security'), ('performance', 'test'), ('development', 'efficiency'), ('test', 'result'), ('v', 'based'), ('v', 'proportion'), ('recognition', 'efficiency'), ('vision', 'system'), ('19', '4'), ('based', 'ai'), ('realize', 'intelligent'), ('certain', 'requirement'), ('requirement', 'improve'), ('interaction', 'target'), ('positive', 'evaluation'), ('x', '16'), ('application', 'requirement'), ('efficiency', 'certain'), ('hardware', 'design'), ('accounted', '19'), ('embedded', 'system'), ('field', 'received'), ('student', 'expert'), ('showed', 'condition'), ('4', 'negative'), ('however', 'positive'), ('application', 'artificial'), ('computer', 'performance'), ('robot', 'interaction'), ('system', 'indicated'), ('data', 'analysis'), ('hampered', 'problem'), ('visual', 'platform'), ('expert', '83'), ('system', 'performance'), ('proportion', 'positive'), ('improve', 'system'), ('platform', 'combined'), ('result', 'practical'), ('target', 'detection'), ('96', 'however'), ('83', '5'), ('technology', 'certain'), ('evaluation', 'accounted'), ('relationship', 'ai'), ('analysis', 'human'), ('ep', 'vision'), ('smart', 'home'), ('condition', 'student'), ('meet', 'actual'), ('x', 'meet'), ('technology', 'platform'), ('present', 'application'), ('paper', 'designed'), ('human', 'computer'), ('ep', 'v'), ('requirement', 'computer'), ('achieved', 'remarkable'), ('function', 'showed'), ('performance', 'also'), ('showed', 'positive'), ('response', 'however'), ('industrial', 'control'), ('overall', 'development'), ('intelligence', 'ai'), ('home', 'field'), ('negative', 'evaluation'), ('face', 'problem'), ('much', 'higher'), ('application', 'development'), ('support', 'vector'), ('artificial', 'intelligence'), ('indicated', 'system'), ('practical', 'application'), ('problem', 'network'), ('efficiency', 'unstable'), ('system', 'achieved'), ('vector', 'machine'), ('10', 'negative'), ('extent', 'however')}\n",
      "Tipo de plagio: Parafraseo o reordenamiento de frases\n",
      "Coincidencias para el plagio:\n",
      "----------------------------\n",
      "Cadena original: (Longitud: 1060)\n",
      "Cadena plagiada:  (Longitud: 1146)\n",
      "\n",
      "Titulo: FID-05.txt\n",
      "Similitud entre 'FID-05.txt' y 'org-085.txt': 96.28%\n",
      "ngrams originales:  {('result', 'rarely'), ('receives', 'collected'), ('collected', 'data'), ('five', 'available'), ('controller', 'receives'), ('dataset', 'proposed'), ('achieves', 'overall'), ('cardio', 'proposed'), ('whereas', 'mabc'), ('novel', 'recommendation'), ('validated', 'cloud'), ('service', 'patient'), ('accuracy', '99'), ('fast', 'preventative'), ('physical', 'dietary'), ('achieves', '86'), ('cloudsim', 'using'), ('sensor', 'glucose'), ('cardiac', 'disease'), ('93', '63'), ('medical', 'service'), ('diagnosis', 'treatment'), ('class', 'recommendation'), ('model', 'implemented'), ('ecg', 'sensor'), ('providing', 'prior'), ('sensor', 'arduino'), ('rarely', 'accurate'), ('91', '88'), ('bigru', 'bidirectional'), ('iot', 'network'), ('cardiovascular', 'disease'), ('user', 'mobile'), ('disease', 'prediction'), ('gated', 'recurrent'), ('proposed', 'providing'), ('disease', 'complex'), ('cardiac', 'patient'), ('attention', 'model'), ('88', '65'), ('patient', 'based'), ('provide', 'fast'), ('63', 'respectively'), ('90', 'whereas'), ('deep', 'cardio'), ('collected', 'patientâ'), ('using', 'four'), ('complex', 'task'), ('sensor', 'predict'), ('glucose', 'sensor'), ('65', '93'), ('healthcare', 'application'), ('prediction', 'model'), ('using', 'real'), ('diagnose', 'cardiovascular'), ('arduino', 'controller'), ('prediction', 'using'), ('sensor', 'ecg'), ('mabc', 'svm'), ('99', '90'), ('using', 'bigru'), ('disease', 'classify'), ('predict', 'diagnose'), ('recurrent', 'unit'), ('diagnose', 'disease'), ('real', 'time'), ('cardio', 'method'), ('hcbda', 'mlbpm'), ('data', 'collected'), ('pulse', 'sensor'), ('diagnosis', 'result'), ('thing', 'iot'), ('sensor', 'pulse'), ('data', 'via'), ('internet', 'thing'), ('cardiovascular', 'class'), ('framinghamâ', 'statlog'), ('system', 'cardiovascular'), ('method', 'achieves'), ('86', '91'), ('issue', 'novel'), ('performance', 'deep'), ('task', 'diagnosis'), ('prior', 'diagnosis'), ('cloud', 'simulator'), ('sensor', 'pressure'), ('available', 'cardiovascular'), ('however', 'predicting'), ('implemented', 'using'), ('pressure', 'sensor'), ('provides', 'physical'), ('remote', 'healthcare'), ('bio', 'sensor'), ('unit', 'attention'), ('classify', 'five'), ('cardio', 'validated'), ('disease', 'initially'), ('mlbpm', 'method'), ('using', 'iot'), ('time', 'framinghamâ'), ('recommendation', 'system'), ('disease', 'dataset'), ('heart', 'disease'), ('recommendation', 'cardiac'), ('application', 'provide'), ('address', 'issue'), ('patientâ', 'remotely'), ('via', 'user'), ('preventative', 'medical'), ('overall', 'accuracy'), ('based', 'classified'), ('four', 'bio'), ('data', 'iot'), ('remotely', 'using'), ('patient', 'risk'), ('dietary', 'recommendation'), ('bidirectional', 'gated'), ('iot', 'based'), ('initially', 'physiological'), ('disease', 'cardiovascular'), ('predicting', 'heart'), ('application', 'performance'), ('treatment', 'dietary'), ('classified', 'data'), ('mobile', 'application'), ('based', 'remote'), ('statlog', 'heart'), ('system', 'provides'), ('physiological', 'data'), ('model', 'diagnose'), ('proposed', 'deep'), ('svm', 'hcbda'), ('accurate', 'address'), ('iot', 'sensor'), ('network', 'deep'), ('simulator', 'cloudsim'), ('risk', 'however')}\n",
      "ngrams plagio:  {('result', 'rarely'), ('collected', 'data'), ('five', 'available'), ('dataset', 'proposed'), ('cardio', 'proposed'), ('whereas', 'mabc'), ('classified', 'five'), ('novel', 'recommendation'), ('validated', 'cloud'), ('service', 'patient'), ('accuracy', '99'), ('fast', 'preventative'), ('physical', 'dietary'), ('cloudsim', 'using'), ('sensor', 'glucose'), ('cardiac', 'disease'), ('93', '63'), ('medical', 'service'), ('diagnosis', 'treatment'), ('diagnosed', 'cardiovascular'), ('class', 'recommendation'), ('model', 'diagnosed'), ('model', 'implemented'), ('ecg', 'sensor'), ('providing', 'prior'), ('sensor', 'arduino'), ('rarely', 'accurate'), ('91', '88'), ('bigru', 'bidirectional'), ('iot', 'network'), ('cardiovascular', 'disease'), ('user', 'mobile'), ('disease', 'prediction'), ('gated', 'recurrent'), ('proposed', 'providing'), ('disease', 'complex'), ('cardiac', 'patient'), ('attention', 'model'), ('88', '65'), ('patient', 'based'), ('63', 'respectively'), ('90', 'whereas'), ('deep', 'cardio'), ('collected', 'patientâ'), ('using', 'four'), ('complex', 'task'), ('sensor', 'predict'), ('glucose', 'sensor'), ('65', '93'), ('healthcare', 'application'), ('prediction', 'model'), ('using', 'real'), ('arduino', 'controller'), ('prediction', 'using'), ('sensor', 'ecg'), ('mabc', 'svm'), ('99', '90'), ('provided', 'fast'), ('using', 'bigru'), ('disease', 'classified'), ('predict', 'diagnose'), ('recurrent', 'unit'), ('diagnose', 'disease'), ('real', 'time'), ('received', 'collected'), ('cardio', 'method'), ('hcbda', 'mlbpm'), ('data', 'collected'), ('pulse', 'sensor'), ('diagnosis', 'result'), ('thing', 'iot'), ('sensor', 'pulse'), ('data', 'via'), ('internet', 'thing'), ('cardiovascular', 'class'), ('framinghamâ', 'statlog'), ('system', 'cardiovascular'), ('86', '91'), ('issue', 'novel'), ('performance', 'deep'), ('task', 'diagnosis'), ('prior', 'diagnosis'), ('cloud', 'simulator'), ('sensor', 'pressure'), ('available', 'cardiovascular'), ('however', 'predicting'), ('implemented', 'using'), ('pressure', 'sensor'), ('system', 'provided'), ('remote', 'healthcare'), ('bio', 'sensor'), ('unit', 'attention'), ('provided', 'physical'), ('cardio', 'validated'), ('disease', 'initially'), ('controller', 'received'), ('mlbpm', 'method'), ('using', 'iot'), ('time', 'framinghamâ'), ('recommendation', 'system'), ('disease', 'dataset'), ('heart', 'disease'), ('recommendation', 'cardiac'), ('method', 'achieved'), ('address', 'issue'), ('patientâ', 'remotely'), ('via', 'user'), ('preventative', 'medical'), ('overall', 'accuracy'), ('based', 'classified'), ('four', 'bio'), ('achieved', 'overall'), ('data', 'iot'), ('remotely', 'using'), ('patient', 'risk'), ('dietary', 'recommendation'), ('bidirectional', 'gated'), ('iot', 'based'), ('initially', 'physiological'), ('disease', 'cardiovascular'), ('predicting', 'heart'), ('application', 'performance'), ('treatment', 'dietary'), ('classified', 'data'), ('mobile', 'application'), ('achieved', '86'), ('application', 'provided'), ('based', 'remote'), ('statlog', 'heart'), ('physiological', 'data'), ('proposed', 'deep'), ('svm', 'hcbda'), ('accurate', 'address'), ('iot', 'sensor'), ('network', 'deep'), ('simulator', 'cloudsim'), ('risk', 'however')}\n",
      "Tipo de plagio: Parafraseo o reordenamiento de frases\n",
      "Coincidencias para el plagio:\n",
      "----------------------------\n",
      "Cadena original: (Longitud: 1165)\n",
      "Cadena plagiada:  (Longitud: 1169)\n",
      "\n",
      "Titulo: FID-09.txt\n",
      "Similitud entre 'FID-09.txt' y 'org-109.txt': 94.06%\n",
      "ngrams originales:  {('discovery', 'process'), ('impose', 'hurdle'), ('implementation', 'artificial'), ('learning', 'technology'), ('deep', 'learning'), ('developed', 'modeling'), ('modeling', 'quantitative'), ('management', 'technique'), ('proteomics', 'microarray'), ('critical', 'support'), ('microarray', 'data'), ('strengthens', 'implementation'), ('scientist', 'however'), ('area', 'machine'), ('impact', 'mankind'), ('play', 'crucial'), ('cost', 'impose'), ('eventually', 'impact'), ('clinical', 'trial'), ('technology', 'play'), ('data', 'mining'), ('peptide', 'synthesis'), ('design', 'discovery'), ('activity', 'relationship'), ('chemical', 'scientist'), ('drug', 'design'), ('development', 'word'), ('novel', 'data'), ('implemented', 'several'), ('challenge', 'impact'), ('process', 'peptide'), ('artificial', 'neural'), ('big', 'data'), ('company', 'chemical'), ('excellent', 'opportunity'), ('pharmaceutical', 'company'), ('structure', 'based'), ('virtual', 'screening'), ('data', 'clinical'), ('obstacle', 'drug'), ('drug', 'monitoring'), ('repositioning', 'polypharmacology'), ('learning', 'algorithm'), ('learning', 'deep'), ('provided', 'critical'), ('provide', 'excellent'), ('evidence', 'past'), ('time', 'consumption'), ('role', 'drug'), ('polypharmacology', 'physiochemical'), ('toxicity', 'prediction'), ('delivery', 'time'), ('algorithm', 'summary'), ('technique', 'provided'), ('impact', 'drug'), ('process', 'eventually'), ('neural', 'network'), ('impose', 'obstacle'), ('recently', 'developed'), ('discovery', 'pipeline'), ('advancement', 'provide'), ('screening', 'toxicity'), ('prediction', 'drug'), ('monitoring', 'release'), ('crucial', 'role'), ('activity', 'evidence'), ('drug', 'designing'), ('designing', 'development'), ('genomics', 'proteomics'), ('modernized', 'area'), ('past', 'strengthens'), ('learning', 'advancement'), ('drug', 'repositioning'), ('consumption', 'high'), ('efficacy', 'target'), ('machine', 'learning'), ('mining', 'curation'), ('low', 'efficacy'), ('target', 'delivery'), ('data', 'genomics'), ('algorithm', 'modernized'), ('synthesis', 'structure'), ('several', 'drug'), ('structureâ', 'activity'), ('based', 'virtual'), ('important', 'area'), ('pharmacophore', 'modeling'), ('discovery', 'complex'), ('field', 'moreover'), ('moreover', 'novel'), ('algorithm', 'implemented'), ('curation', 'management'), ('opportunity', 'rational'), ('area', 'research'), ('hurdle', 'challenge'), ('development', 'important'), ('quantitative', 'structureâ'), ('discovery', 'development'), ('pipeline', 'artificial'), ('modeling', 'algorithm'), ('trial', 'also'), ('relationship', 'drug'), ('learning', 'field'), ('also', 'impose'), ('intelligence', 'machine'), ('physiochemical', 'activity'), ('intelligence', 'deep'), ('release', 'pharmacophore'), ('research', 'pharmaceutical'), ('rational', 'drug'), ('high', 'cost'), ('word', 'artificial'), ('artificial', 'intelligence'), ('drug', 'discovery'), ('summary', 'artificial'), ('complex', 'big'), ('support', 'recently'), ('however', 'low'), ('network', 'deep'), ('ligand', 'based'), ('screening', 'ligand')}\n",
      "ngrams plagio:  {('discovery', 'process'), ('historical', 'evidence'), ('impose', 'hurdle'), ('implementation', 'artificial'), ('summary', 'advancement'), ('deep', 'learning'), ('learning', 'technology'), ('developed', 'modeling'), ('modeling', 'quantitative'), ('particularly', 'use'), ('management', 'technique'), ('proteomics', 'microarray'), ('development', 'particularly'), ('critical', 'support'), ('microarray', 'data'), ('strengthens', 'implementation'), ('scientist', 'however'), ('use', 'artificial'), ('area', 'machine'), ('impact', 'mankind'), ('play', 'crucial'), ('cost', 'impose'), ('cost', 'hinder'), ('eventually', 'impact'), ('clinical', 'trial'), ('algorithm', 'technology'), ('data', 'mining'), ('technology', 'play'), ('peptide', 'synthesis'), ('implementation', 'ai'), ('newly', 'developed'), ('volume', 'data'), ('technology', 'modernized'), ('design', 'discovery'), ('revolutionized', 'drug'), ('activity', 'relationship'), ('chemical', 'scientist'), ('complexity', 'volume'), ('drug', 'design'), ('development', 'word'), ('novel', 'data'), ('implemented', 'several'), ('challenge', 'impact'), ('process', 'peptide'), ('artificial', 'neural'), ('big', 'data'), ('company', 'chemical'), ('excellent', 'opportunity'), ('pharmaceutical', 'company'), ('structure', 'based'), ('virtual', 'screening'), ('data', 'clinical'), ('obstacle', 'drug'), ('drug', 'monitoring'), ('repositioning', 'polypharmacology'), ('learning', 'algorithm'), ('learning', 'deep'), ('additionally', 'complexity'), ('provided', 'critical'), ('represent', 'crucial'), ('provide', 'excellent'), ('evidence', 'past'), ('time', 'consumption'), ('role', 'drug'), ('polypharmacology', 'physiochemical'), ('including', 'peptide'), ('toxicity', 'prediction'), ('delivery', 'time'), ('algorithm', 'summary'), ('mankind', 'drug'), ('development', 'represent'), ('technique', 'provided'), ('ml', 'technology'), ('impact', 'drug'), ('process', 'eventually'), ('neural', 'network'), ('impose', 'obstacle'), ('ai', 'machine'), ('learning', 'drug'), ('recently', 'developed'), ('advancement', 'ai'), ('discovery', 'pipeline'), ('discovery', 'furthermore'), ('advancement', 'provide'), ('hinder', 'progress'), ('progress', 'drug'), ('screening', 'toxicity'), ('prediction', 'drug'), ('monitoring', 'release'), ('crucial', 'role'), ('process', 'drug'), ('activity', 'evidence'), ('drug', 'designing'), ('designing', 'development'), ('genomics', 'proteomics'), ('trial', 'pose'), ('modernized', 'area'), ('past', 'strengthens'), ('learning', 'advancement'), ('drug', 'repositioning'), ('consumption', 'high'), ('efficacy', 'target'), ('various', 'process'), ('learning', 'offer'), ('machine', 'learning'), ('mining', 'curation'), ('evidence', 'support'), ('low', 'efficacy'), ('target', 'delivery'), ('data', 'genomics'), ('synthesis', 'structure'), ('algorithm', 'modernized'), ('several', 'drug'), ('crucial', 'area'), ('based', 'virtual'), ('structureâ', 'activity'), ('important', 'area'), ('pharmacophore', 'modeling'), ('offer', 'significant'), ('benefiting', 'mankind'), ('discovery', 'complex'), ('field', 'moreover'), ('modernized', 'various'), ('discovery', 'including'), ('curation', 'management'), ('algorithm', 'implemented'), ('moreover', 'novel'), ('opportunity', 'rational'), ('ai', 'deep'), ('area', 'research'), ('hurdle', 'challenge'), ('development', 'important'), ('quantitative', 'structureâ'), ('discovery', 'development'), ('pipeline', 'artificial'), ('technology', 'revolutionized'), ('modeling', 'algorithm'), ('significant', 'opportunity'), ('learning', 'ml'), ('relationship', 'drug'), ('trial', 'also'), ('learning', 'field'), ('however', 'challenge'), ('also', 'impose'), ('intelligence', 'machine'), ('physiochemical', 'activity'), ('challenge', 'low'), ('intelligence', 'deep'), ('release', 'pharmacophore'), ('research', 'pharmaceutical'), ('pose', 'significant'), ('rational', 'drug'), ('intelligence', 'ai'), ('support', 'implementation'), ('high', 'cost'), ('significant', 'obstacle'), ('word', 'artificial'), ('support', 'newly'), ('artificial', 'intelligence'), ('furthermore', 'novel'), ('discovery', 'ultimately'), ('ultimately', 'benefiting'), ('drug', 'discovery'), ('summary', 'artificial'), ('activity', 'historical'), ('complex', 'big'), ('support', 'recently'), ('however', 'low'), ('network', 'deep'), ('ligand', 'based'), ('discovery', 'additionally'), ('screening', 'ligand')}\n",
      "Tipo de plagio: Reordenamiento de frases\n",
      "Coincidencias para el plagio:\n",
      "----------------------------\n",
      "Cadena original: (Longitud: 1189)\n",
      "Cadena plagiada:  (Longitud: 2349)\n",
      "\n",
      "Titulo: FID-08.txt\n",
      "Similitud entre 'FID-08.txt' y 'org-079.txt': 92.26%\n",
      "ngrams originales:  {('hierarchical', 'fuzzy'), ('indicator', 'int'), ('proposed', 'methodological'), ('construction', 'equipment'), ('integrate', 'consideration'), ('decision', 'making'), ('f1', 'state'), ('built', 'designing'), ('group', 'indicator'), ('basis', 'group'), ('v9', 'v10'), ('provide', 'appropriate'), ('current', 'work'), ('r', 'v1'), ('fuzzy', 'logical'), ('high', 'e'), ('number', 'fuzzy'), ('system', 'performing'), ('base', 'output'), ('risk', 'management'), ('membership', 'function'), ('performing', 'calculation'), ('application', 'fuzzy'), ('study', 'proposed'), ('statement', 'mathematical'), ('f4', 'indicator'), ('requires', 'system'), ('managing', 'personnel'), ('work', 'foreign'), ('group', 'construction'), ('fuzzy', 'coefficient'), ('mathematical', 'model'), ('numerical', 'experiment'), ('turn', 'also'), ('h', 'v8'), ('following', 'structural'), ('efficiency', 'use'), ('appropriate', 'recommendation'), ('f4', 'q'), ('system', 'â'), ('mathematical', 'problem'), ('enterprise', 'made'), ('v3', 'f2'), ('set', 'proposed'), ('theory', 'fuzzy'), ('within', 'three'), ('comparative', 'analysis'), ('system', 'built'), ('constructed', 'system'), ('movement', 'indicator'), ('function', 'r'), ('solution', 'methodological'), ('personnel', 'risk'), ('approach', 'used'), ('logic', 'allows'), ('indicator', 'significantly'), ('substantiation', 'set'), ('q', 'f'), ('formalized', 'information'), ('written', 'group'), ('low', 'medium'), ('v8', 'v9'), ('considered', 'intelligent'), ('output', 'variable'), ('research', 'systemcomplex'), ('change', 'input'), ('staff', 'turnover'), ('turnover', 'â'), ('v2', 'v3'), ('int', 'f'), ('main', 'idea'), ('possible', 'identify'), ('made', 'possible'), ('enterprise', 'statement'), ('existing', 'one'), ('level', 'turn'), ('three', 'term'), ('apparatus', 'fuzzy'), ('v6', 'v7'), ('one', 'integrate'), ('idea', 'paper'), ('functional', 'â'), ('contrast', 'existing'), ('f1', 'r'), ('work', 'considers'), ('e', 'formalized'), ('increase', 'efficiency'), ('v5', 'v6'), ('built', 'mathematical'), ('1ã', '12'), ('g', 'v4'), ('variable', 'functional'), ('use', 'constructed'), ('based', 'apparatus'), ('calculation', 'help'), ('f4', 'personnel'), ('component', 'built'), ('information', 'variable'), ('scientific', 'abstraction'), ('domestic', 'scientist'), ('manufacturer', 'analysis'), ('mechanism', 'structural'), ('adverse', 'situation'), ('element', 'computational'), ('used', 'study'), ('enterprise', 'numerical'), ('study', 'classic'), ('r', 'g'), ('f3', 'motivational'), ('theoretical', 'research'), ('apparatus', 'order'), ('fst', 'make'), ('problem', 'personnel'), ('provision', 'fundamental'), ('assessment', 'personnel'), ('state', 'qualification'), ('rule', 'base'), ('substantiation', 'methodological'), ('logic', 'apparatus'), ('inference', 'considered'), ('vary', 'within'), ('element', 'component'), ('result', 'assessing'), ('f', 'f1'), ('namely', 'four'), ('modern', 'theoretical'), ('method', 'formalization'), ('scientist', 'statistical'), ('cost', 'event'), ('level', 'personnel'), ('event', 'adverse'), ('enterprise', 'method'), ('basis', 'study'), ('indicator', 'using'), ('coefficient', 'twelve'), ('methodological', 'approach'), ('basis', 'fst'), ('based', 'application'), ('coefficient', 'f1'), ('v4', 'v5'), ('f2', 'g'), ('intelligent', 'us'), ('systemcomplex', 'approach'), ('medium', 'g'), ('qualification', 'intellectual'), ('f1', 'f2'), ('indicator', 'function'), ('fuzzy', 'logic'), ('analysis', 'scientific'), ('given', 'variable'), ('condition', 'uncertainty'), ('consideration', 'qualitative'), ('enterprise', 'based'), ('considers', 'hierarchical'), ('data', 'result'), ('abstraction', 'generalization'), ('unknown', 'function'), ('fuzzy', 'system'), ('â', 'f1'), ('set', 'measure'), ('problem', 'managing'), ('vi', '1ã'), ('input', 'data'), ('problem', 'work'), ('evaluation', 'change'), ('recommendation', 'solution'), ('g', 'h'), ('formalization', 'basis'), ('integrated', 'indicator'), ('theory', 'comparative'), ('input', 'output'), ('g', 'high'), ('assessing', 'personnel'), ('element', 'membership'), ('quantitative', 'composition'), ('variable', 'written'), ('result', 'research'), ('method', 'fuzzy'), ('quantitative', 'indicator'), ('conducted', 'basis'), ('intelligence', 'particular'), ('possible', 'estimate'), ('risk', 'personnel'), ('assessing', 'level'), ('scientific', 'experience'), ('â', 'integrated'), ('estimate', 'level'), ('make', 'possible'), ('v11', 'v12'), ('variable', 'expert'), ('risk', 'level'), ('designing', 'fuzzy'), ('management', 'provide'), ('measure', 'increase'), ('qualitative', 'quantitative'), ('h', 'q'), ('approach', 'assessment'), ('value', 'function'), ('v10', 'f4'), ('experience', 'modern'), ('making', 'condition'), ('variable', 'rule'), ('system', 'following'), ('foreign', 'domestic'), ('indicator', 'assessing'), ('equipment', 'manufacturer'), ('â', 'f3'), ('v1', 'v2'), ('twelve', 'current'), ('risk', 'enterprise'), ('f2', 'staff'), ('data', 'rule'), ('output', 'mechanism'), ('computational', 'intelligence'), ('statistical', 'data'), ('enables', 'substantiation'), ('efficiency', 'decision'), ('intellectual', 'potential'), ('fuzzy', 'value'), ('composition', 'â'), ('problem', 'assessing'), ('â', 'f4'), ('ï', 'main'), ('motivational', 'system'), ('also', 'fuzzy'), ('four', 'group'), ('f2', 'f3'), ('expert', 'evaluation'), ('personnel', 'movement'), ('rule', 'vary'), ('system', 'fuzzy'), ('using', 'fuzzy'), ('â', 'f2'), ('fundamental', 'work'), ('fuzzy', 'data'), ('uncertainty', 'reduce'), ('experiment', 'conducted'), ('potential', 'â'), ('indicator', 'different'), ('set', 'theory'), ('f', 'unknown'), ('methodological', 'basis'), ('research', 'problem'), ('fuzzy', 'set'), ('term', 'low'), ('approach', 'assessing'), ('â', 'vi'), ('function', 'input'), ('function', 'given'), ('help', 'requires'), ('paper', 'substantiation'), ('classic', 'provision'), ('generalization', 'scientific'), ('data', 'namely'), ('q', 'v11'), ('v12', 'output'), ('particular', 'theory'), ('allows', 'contrast'), ('v7', 'f3'), ('logical', 'inference'), ('model', 'method'), ('risk', 'quantitative'), ('reduce', 'cost'), ('significantly', 'increase'), ('us', 'element'), ('function', 'fuzzy'), ('identify', 'problem'), ('12', 'indicator'), ('f3', 'f4'), ('analysis', 'result'), ('structural', 'element'), ('different', 'number'), ('enterprise', 'enables'), ('order', 'identify'), ('f3', 'h'), ('work', 'â')}\n",
      "ngrams plagio:  {('hierarchical', 'fuzzy'), ('level', 'justifying'), ('proposed', 'methodological'), ('performing', 'calculation'), ('statement', 'mathematical'), ('requires', 'system'), ('cost', 'adverse'), ('work', 'foreign'), ('data', 'change'), ('enhancing', 'decision'), ('following', 'structural'), ('efficiency', 'use'), ('coefficient', 'vi'), ('integrates', 'qualitative'), ('system', 'built'), ('solution', 'methodological'), ('approach', 'used'), ('manufacturer', 'considers'), ('q', 'f'), ('low', 'medium'), ('representing', 'personnel'), ('output', 'variable'), ('change', 'input'), ('staff', 'turnover'), ('main', 'idea'), ('enterprise', 'statement'), ('three', 'term'), ('risk', 'problem'), ('increase', 'efficiency'), ('built', 'mathematical'), ('g', 'v4'), ('adverse', 'situation'), ('uncertainty', 'reducing'), ('element', 'computational'), ('study', 'classic'), ('r', 'g'), ('employed', 'study'), ('f3', 'motivational'), ('apparatus', 'order'), ('evaluation', 'input'), ('fst', 'make'), ('assessment', 'personnel'), ('event', 'adverse'), ('method', 'formalization'), ('identify', 'provide'), ('indicator', 'fuzzy'), ('basis', 'fst'), ('based', 'application'), ('v4', 'v5'), ('f2', 'g'), ('intelligent', 'us'), ('systemcomplex', 'approach'), ('medium', 'g'), ('given', 'variable'), ('consideration', 'qualitative'), ('enterprise', 'based'), ('fuzzy', 'system'), ('problem', 'work'), ('evaluation', 'change'), ('integrated', 'indicator'), ('system', 'structural'), ('existing', 'method'), ('f', 'function'), ('intelligence', 'particular'), ('possible', 'estimate'), ('logic', 'goal'), ('risk', 'level'), ('experience', 'modern'), ('making', 'condition'), ('variable', 'rule'), ('equipment', 'manufacturer'), ('utilizes', 'fuzzy'), ('function', 'rule'), ('coefficient', 'reflecting'), ('using', 'fuzzy'), ('fuzzy', 'data'), ('potential', 'â'), ('research', 'problem'), ('â', 'vi'), ('paper', 'substantiation'), ('v12', 'output'), ('inference', 'system'), ('significantly', 'increase'), ('system', 'considered'), ('work', 'â'), ('indicator', 'int'), ('employ', 'computational'), ('provide', 'appropriate'), ('reducing', 'cost'), ('number', 'fuzzy'), ('potential', 'f2'), ('application', 'fuzzy'), ('12', 'output'), ('numerical', 'experiment'), ('theory', 'fuzzy'), ('within', 'three'), ('comparative', 'analysis'), ('written', 'group'), ('formalized', 'information'), ('reflecting', 'expert'), ('possible', 'identify'), ('existing', 'one'), ('one', 'integrate'), ('1ã', '12'), ('based', 'apparatus'), ('scientific', 'abstraction'), ('mechanism', 'structural'), ('particularly', 'fuzzy'), ('system', 'allows'), ('used', 'study'), ('estimating', 'personnel'), ('indicator', 'quantitative'), ('rule', 'base'), ('substantiation', 'methodological'), ('f', 'f1'), ('provide', 'recommendation'), ('basis', 'study'), ('methodological', 'approach'), ('coefficient', 'f1'), ('int', 'representing'), ('qualification', 'intellectual'), ('f1', 'f2'), ('fuzzy', 'logic'), ('analysis', 'scientific'), ('condition', 'uncertainty'), ('unknown', 'function'), ('including', 'membership'), ('vi', '1ã'), ('formalization', 'basis'), ('risk', 'personnel'), ('change', 'low'), ('recommendation', 'managing'), ('research', 'method'), ('management', 'provide'), ('measure', 'increase'), ('value', 'function'), ('v10', 'f4'), ('mechanism', 'system'), ('system', 'following'), ('v1', 'v2'), ('twelve', 'current'), ('intellectual', 'potential'), ('also', 'fuzzy'), ('four', 'group'), ('expert', 'evaluation'), ('personnel', 'movement'), ('level', 'exemplified'), ('approach', 'employed'), ('set', 'theory'), ('f', 'unknown'), ('theory', 'methodological'), ('function', 'input'), ('function', 'given'), ('help', 'requires'), ('classic', 'provision'), ('generalization', 'scientific'), ('particular', 'theory'), ('model', 'method'), ('risk', 'quantitative'), ('introduces', 'unknown'), ('12', 'indicator'), ('structural', 'element'), ('different', 'number'), ('proposes', 'methodological'), ('f3', 'h'), ('integrate', 'consideration'), ('group', 'indicator'), ('current', 'work'), ('fuzzy', 'logical'), ('membership', 'function'), ('study', 'proposed'), ('f4', 'indicator'), ('managing', 'personnel'), ('includes', 'classic'), ('h', 'v8'), ('appropriate', 'recommendation'), ('f4', 'q'), ('system', 'â'), ('v3', 'f2'), ('movement', 'indicator'), ('indicator', 'significantly'), ('personnel', 'risk'), ('variable', 'integrated'), ('substantiation', 'set'), ('data', 'comprising'), ('v8', 'v9'), ('considered', 'intelligent'), ('research', 'systemcomplex'), ('turnover', 'â'), ('v2', 'v3'), ('int', 'f'), ('made', 'possible'), ('apparatus', 'fuzzy'), ('v6', 'v7'), ('system', 'f4'), ('foundation', 'includes'), ('f1', 'r'), ('work', 'considers'), ('v5', 'v6'), ('turnover', 'f3'), ('use', 'constructed'), ('goal', 'identify'), ('calculation', 'help'), ('f4', 'personnel'), ('component', 'built'), ('information', 'variable'), ('domestic', 'scientist'), ('paper', 'introduces'), ('complex', 'approach'), ('enterprise', 'numerical'), ('study', 'utilizes'), ('theoretical', 'research'), ('medium', 'high'), ('generalization', 'modern'), ('problem', 'personnel'), ('provision', 'fundamental'), ('composition', 'f1'), ('state', 'qualification'), ('data', 'team'), ('allows', 'estimating'), ('vary', 'within'), ('element', 'component'), ('situation', 'paper'), ('modern', 'theoretical'), ('cost', 'event'), ('level', 'paper'), ('level', 'personnel'), ('enterprise', 'method'), ('intelligent', 'employ'), ('indicator', 'function'), ('abstraction', 'generalization'), ('set', 'measure'), ('input', 'data'), ('theory', 'comparative'), ('element', 'membership'), ('conducted', 'basis'), ('assessing', 'level'), ('scientific', 'experience'), ('â', 'integrated'), ('estimate', 'level'), ('approach', 'integrates'), ('intelligence', 'element'), ('system', 'complex'), ('distinguishing', 'existing'), ('h', 'q'), ('element', 'particularly'), ('enterprise', 'using'), ('indicator', 'assessing'), ('â', 'f3'), ('risk', 'enterprise'), ('data', 'rule'), ('computational', 'intelligence'), ('team', 'research'), ('composition', 'â'), ('problem', 'assessing'), ('â', 'f4'), ('f2', 'f3'), ('system', 'fuzzy'), ('â', 'f2'), ('fundamental', 'work'), ('uncertainty', 'reduce'), ('experiment', 'conducted'), ('indicator', 'different'), ('methodological', 'basis'), ('term', 'low'), ('q', 'v11'), ('study', 'proposes'), ('v7', 'f3'), ('measure', 'enhance'), ('reduce', 'cost'), ('function', 'fuzzy'), ('substantiates', 'methodological'), ('analysis', 'result'), ('provision', 'foreign'), ('construction', 'equipment'), ('decision', 'making'), ('f1', 'state'), ('built', 'designing'), ('paper', 'substantiates'), ('basis', 'group'), ('v9', 'v10'), ('r', 'v1'), ('high', 'e'), ('system', 'performing'), ('indicator', 'enhancing'), ('base', 'output'), ('risk', 'management'), ('element', 'including'), ('group', 'construction'), ('fuzzy', 'coefficient'), ('mathematical', 'model'), ('turn', 'also'), ('mathematical', 'problem'), ('enterprise', 'made'), ('set', 'proposed'), ('making', 'efficiency'), ('constructed', 'system'), ('function', 'r'), ('situation', 'distinguishing'), ('logic', 'allows'), ('level', 'turn'), ('idea', 'paper'), ('functional', 'â'), ('contrast', 'existing'), ('e', 'formalized'), ('variable', 'functional'), ('manufacturer', 'analysis'), ('comprising', 'four'), ('efficiency', 'fuzzy'), ('logic', 'apparatus'), ('inference', 'considered'), ('result', 'assessing'), ('namely', 'four'), ('scientist', 'statistical'), ('indicator', 'using'), ('coefficient', 'twelve'), ('problem', 'study'), ('considers', 'hierarchical'), ('data', 'result'), ('â', 'f1'), ('study', 'foundation'), ('problem', 'managing'), ('recommendation', 'solution'), ('g', 'h'), ('input', 'output'), ('high', 'study'), ('g', 'high'), ('assessing', 'personnel'), ('quantitative', 'composition'), ('variable', 'written'), ('result', 'research'), ('method', 'fuzzy'), ('quantitative', 'indicator'), ('make', 'possible'), ('v11', 'v12'), ('variable', 'expert'), ('designing', 'fuzzy'), ('qualitative', 'quantitative'), ('approach', 'assessment'), ('foreign', 'domestic'), ('f2', 'staff'), ('output', 'mechanism'), ('exemplified', 'group'), ('statistical', 'data'), ('enables', 'substantiation'), ('efficiency', 'decision'), ('fuzzy', 'value'), ('enhance', 'efficiency'), ('research', 'system'), ('ï', 'main'), ('motivational', 'system'), ('rule', 'vary'), ('justifying', 'measure'), ('fuzzy', 'set'), ('approach', 'assessing'), ('efficiency', 'uncertainty'), ('allows', 'contrast'), ('data', 'namely'), ('logical', 'inference'), ('us', 'element'), ('identify', 'problem'), ('f3', 'f4'), ('enterprise', 'enables'), ('order', 'identify')}\n",
      "Tipo de plagio: Reordenamiento de frases\n",
      "Coincidencias para el plagio:\n",
      "----------------------------\n",
      "Cadena original: (Longitud: 2443)\n",
      "Cadena plagiada:  (Longitud: 3903)\n",
      "\n",
      "Titulo: FID-06.txt\n",
      "Similitud entre 'FID-06.txt' y 'org-043.txt': 91.83%\n",
      "ngrams originales:  {('data', 'collection'), ('empathy', 'generally'), ('five', 'student'), ('collected', 'data'), ('participant', 'perceive'), ('likely', 'female'), ('uppsala', 'university'), ('human', 'machine'), ('thelevel', 'empathy'), ('exit', 'chatbots'), ('university', 'sweden'), ('analyzed', 'using'), ('chatbot', 'interaction'), ('data', 'manually'), ('anthropomorphic', 'chatbots'), ('result', 'study'), ('methodology', 'five'), ('chatbots', 'without'), ('help', 'politeness'), ('generally', 'low'), ('collection', 'collected'), ('qualitative', 'data'), ('chatbots', 'machine'), ('dynamic', 'semi'), ('manually', 'analyzed'), ('done', 'exploring'), ('interaction', 'amongcomputer'), ('study', 'conducted'), ('showsthat', 'participant'), ('science', 'student'), ('machine', 'human'), ('existence', 'verbalabuse'), ('participant', 'frustrate'), ('ofwhether', 'participant'), ('student', 'uppsala'), ('expressing', 'frustration'), ('question', 'another'), ('however', 'thelevel'), ('expect', 'help'), ('using', 'thematic'), ('chatbots', 'exit'), ('interaction', 'expectation'), ('chatbots', 'likely'), ('dissatisfied', 'theresponse'), ('human', 'existence'), ('interaction', 'regardless'), ('another', 'time'), ('structured', 'interview'), ('might', 'expect'), ('chatbot', 'helpfulness'), ('without', 'expressing'), ('human', 'chatbot'), ('also', 'showsthat'), ('sweden', 'done'), ('conducted', 'investigate'), ('interview', 'methodology'), ('study', 'found'), ('student', 'conductedfor'), ('low', 'participant'), ('found', 'empathy'), ('thematic', 'analysis'), ('dependingon', 'gender'), ('study', 'also'), ('investigate', 'empathy'), ('exploring', 'howparticipants'), ('empathy', 'human'), ('frustration', 'come'), ('howparticipants', 'perceive'), ('participant', 'might'), ('frustration', 'usuallyforget'), ('time', 'study'), ('politeness', 'chatbots'), ('verbalabuse', 'human'), ('semi', 'structured'), ('perceive', 'anthropomorphic'), ('gender', 'dynamic'), ('machine', 'however'), ('frustrate', 'dissatisfied'), ('conductedfor', 'qualitative'), ('regardless', 'ofwhether'), ('theresponse', 'chatbots'), ('usuallyforget', 'frustration'), ('helpfulness', 'dependingon'), ('chatbots', 'human'), ('come', 'question'), ('analysis', 'result'), ('expectation', 'chatbot'), ('amongcomputer', 'science')}\n",
      "ngrams plagio:  {('data', 'collection'), ('empathy', 'generally'), ('five', 'student'), ('collected', 'data'), ('participant', 'perceive'), ('likely', 'female'), ('uppsala', 'university'), ('participant', 'may'), ('human', 'machine'), ('exit', 'chatbots'), ('university', 'sweden'), ('analyzed', 'using'), ('chatbot', 'interaction'), ('abuse', 'human'), ('data', 'manually'), ('participant', 'become'), ('response', 'chatbots'), ('whether', 'participant'), ('exploring', 'participant'), ('anthropomorphic', 'chatbots'), ('result', 'study'), ('methodology', 'five'), ('chatbots', 'without'), ('verbal', 'abuse'), ('help', 'politeness'), ('participant', 'perceived'), ('generally', 'low'), ('collection', 'collected'), ('however', 'level'), ('conducted', 'qualitative'), ('qualitative', 'data'), ('chatbots', 'machine'), ('dynamic', 'semi'), ('manually', 'analyzed'), ('done', 'exploring'), ('student', 'conducted'), ('study', 'conducted'), ('find', 'empathy'), ('frustration', 'came'), ('helpfulness', 'depending'), ('science', 'student'), ('among', 'computer'), ('interaction', 'among'), ('machine', 'human'), ('usually', 'forgot'), ('existence', 'verbal'), ('study', 'find'), ('student', 'uppsala'), ('expressing', 'frustration'), ('dissatisfied', 'response'), ('question', 'another'), ('expect', 'help'), ('level', 'empathy'), ('using', 'thematic'), ('chatbots', 'exit'), ('interaction', 'expectation'), ('chatbots', 'likely'), ('human', 'existence'), ('interaction', 'regardless'), ('another', 'time'), ('structured', 'interview'), ('become', 'frustrated'), ('chatbot', 'helpfulness'), ('without', 'expressing'), ('human', 'chatbot'), ('depending', 'gender'), ('forgot', 'frustration'), ('came', 'question'), ('sweden', 'done'), ('conducted', 'investigate'), ('interview', 'methodology'), ('low', 'participant'), ('thematic', 'analysis'), ('frustration', 'usually'), ('may', 'expect'), ('also', 'showed'), ('regardless', 'whether'), ('study', 'also'), ('investigate', 'empathy'), ('empathy', 'human'), ('time', 'study'), ('perceived', 'anthropomorphic'), ('showed', 'participant'), ('politeness', 'chatbots'), ('semi', 'structured'), ('perceive', 'anthropomorphic'), ('gender', 'dynamic'), ('machine', 'however'), ('frustrated', 'dissatisfied'), ('chatbots', 'human'), ('analysis', 'result'), ('computer', 'science'), ('expectation', 'chatbot')}\n",
      "Tipo de plagio: Parafraseo o inserción de frases\n",
      "Coincidencias para el plagio:\n",
      "----------------------------\n",
      "Cadena original: (Longitud: 864)\n",
      "Cadena plagiada:  (Longitud: 853)\n",
      "\n",
      "Titulo: FID-07.txt\n",
      "Similitud entre 'FID-07.txt' y 'org-041.txt': 88.74%\n",
      "ngrams originales:  {('experience', 'research'), ('implementation', 'artificial'), ('language', 'processing'), ('quality', 'interaction'), ('social', 'customer'), ('context', 'use'), ('use', 'artificial'), ('reviewing', 'various'), ('qualitative', 'reviewing'), ('approach', 'used'), ('strategy', 'improving'), ('affectively', 'socially'), ('responsive', 'humane'), ('natural', 'language'), ('ai', 'interaction'), ('research', 'topic'), ('analysis', 'enable'), ('particular', 'interest'), ('article', 'book'), ('result', 'found'), ('used', 'qualitative'), ('affective', 'social'), ('need', 'emotion'), ('enable', 'ai'), ('study', 'related'), ('ai', 'respond'), ('humane', 'technology'), ('human', 'ai'), ('experience', 'affectively'), ('interaction', 'great'), ('literature', 'data'), ('technology', 'natural'), ('focus', 'development'), ('processing', 'emotion'), ('development', 'responsive'), ('sentiment', 'analysis'), ('various', 'study'), ('experience', 'use'), ('interest', 'due'), ('socially', 'research'), ('research', 'result'), ('due', 'potential'), ('used', 'journal'), ('research', 'approach'), ('sensitively', 'user'), ('aim', 'explore'), ('data', 'source'), ('application', 'artificial'), ('related', 'literature'), ('research', 'aim'), ('journal', 'article'), ('interaction', 'become'), ('user', 'need'), ('explore', 'optimization'), ('technology', 'context'), ('topic', 'research'), ('interaction', 'customer'), ('found', 'implementation'), ('relevant', 'research'), ('recognition', 'sentiment'), ('respond', 'precisely'), ('optimization', 'human'), ('interaction', 'application'), ('strategy', 'human'), ('artificial', 'empathy'), ('book', 'relevant'), ('source', 'used'), ('emotion', 'recognition'), ('strategy', 'particular'), ('use', 'technology'), ('important', 'focus'), ('become', 'important'), ('potential', 'improving'), ('great', 'potential'), ('improving', 'affective'), ('improving', 'customer'), ('precisely', 'sensitively'), ('empathy', 'strategy'), ('customer', 'experience'), ('improve', 'quality'), ('potential', 'improve')}\n",
      "ngrams plagio:  {('significantly', 'improve'), ('experience', 'research'), ('indicate', 'implementing'), ('particularly', 'interesting'), ('language', 'processing'), ('quality', 'interaction'), ('optimize', 'human'), ('socially', 'aim'), ('interaction', 'enhance'), ('social', 'customer'), ('context', 'use'), ('use', 'artificial'), ('humane', 'context'), ('qualitative', 'involving'), ('affectively', 'socially'), ('responsive', 'humane'), ('focus', 'developing'), ('involving', 'review'), ('include', 'journal'), ('natural', 'language'), ('ai', 'interaction'), ('source', 'include'), ('research', 'topic'), ('analysis', 'enable'), ('approach', 'qualitative'), ('article', 'book'), ('developing', 'technology'), ('affective', 'social'), ('need', 'emotion'), ('enable', 'ai'), ('study', 'related'), ('review', 'various'), ('ai', 'respond'), ('human', 'ai'), ('experience', 'affectively'), ('result', 'indicate'), ('literature', 'data'), ('technology', 'natural'), ('processing', 'emotion'), ('sentiment', 'analysis'), ('various', 'study'), ('technology', 'responsive'), ('potential', 'significantly'), ('research', 'result'), ('implementing', 'artificial'), ('research', 'approach'), ('interaction', 'potential'), ('sensitively', 'user'), ('data', 'source'), ('related', 'literature'), ('journal', 'article'), ('interesting', 'potential'), ('interaction', 'become'), ('user', 'need'), ('topic', 'research'), ('interaction', 'customer'), ('improve', 'customer'), ('relevant', 'research'), ('recognition', 'sentiment'), ('respond', 'precisely'), ('aim', 'research'), ('enhance', 'affective'), ('strategy', 'human'), ('strategy', 'optimize'), ('artificial', 'empathy'), ('book', 'relevant'), ('emotion', 'recognition'), ('important', 'focus'), ('become', 'important'), ('experience', 'technology'), ('strategy', 'particularly'), ('precisely', 'sensitively'), ('research', 'explore'), ('explore', 'artificial'), ('empathy', 'strategy'), ('customer', 'experience'), ('improve', 'quality'), ('potential', 'improve')}\n",
      "Tipo de plagio: Inserción de frases\n",
      "Coincidencias para el plagio:\n",
      "----------------------------\n",
      "Cadena original: (Longitud: 781)\n",
      "Cadena plagiada:  (Longitud: 771)\n",
      "\n",
      "Titulo: FID-02.txt\n",
      "Similitud entre 'FID-02.txt' y 'org-104.txt': 87.64%\n",
      "ngrams originales:  {('recent', 'diagnostic'), ('datasets', 'led'), ('fundamental', 'algorithm'), ('transform', 'twenty'), ('performance', 'complex'), ('vehicle', 'language'), ('go', 'review'), ('ml', 'medicine'), ('field', 'include'), ('general', 'microscopy'), ('ml', 'form'), ('language', 'translation'), ('summarise', 'application'), ('form', 'artificial'), ('underlying', 'architecture'), ('approach', 'learning'), ('led', 'increasing'), ('caveat', 'field'), ('learning', 'highlight'), ('review', 'fundamental'), ('competence', 'across'), ('showcase', 'recent'), ('dermatology', 'radiology'), ('pathology', 'general'), ('radiology', 'pathology'), ('increasing', 'computer'), ('learning', 'ml'), ('twenty', 'first'), ('rapid', 'recent'), ('computer', 'competence'), ('chatbots', 'beyond'), ('include', 'driving'), ('game', 'go'), ('behind', 'machine'), ('algorithm', 'growth'), ('placed', 'transform'), ('recent', 'progress'), ('machine', 'learning'), ('across', 'range'), ('learning', 'optimisation'), ('algorithm', 'behind'), ('size', 'datasets'), ('beyond', 'human'), ('growth', 'size'), ('range', 'field'), ('translation', 'chatbots'), ('complex', 'board'), ('medicine', 'particular'), ('architecture', 'algorithm'), ('board', 'game'), ('diagnostic', 'performance'), ('artificial', 'intelligence'), ('first', 'century'), ('application', 'ml'), ('century', 'rapid'), ('driving', 'vehicle'), ('progress', 'underlying'), ('specific', 'approach'), ('particular', 'showcase'), ('intelligence', 'placed'), ('performance', 'caveat'), ('field', 'dermatology'), ('human', 'performance'), ('highlight', 'specific'), ('optimisation', 'summarise')}\n",
      "ngrams plagio:  {('datasets', 'led'), ('ml', 'medicine'), ('underlying', 'architecture'), ('subset', 'feature'), ('led', 'increasing'), ('reduces', 'dimension'), ('algorithm', 'choosing'), ('twenty', 'first'), ('strategy', 'algorithm'), ('algorithm', 'growth'), ('range', 'field'), ('first', 'century'), ('application', 'ml'), ('progress', 'underlying'), ('human', 'performance'), ('highlight', 'specific'), ('ml', 'form'), ('language', 'translation'), ('play', 'important'), ('summarise', 'application'), ('elimination', 'redundant'), ('orient', 'searching'), ('approach', 'learning'), ('review', 'fundamental'), ('field', 'algorithm'), ('solution', 'feature'), ('classification', 'selection'), ('chatbots', 'beyond'), ('include', 'driving'), ('performance', 'machine'), ('behind', 'machine'), ('learning', 'algorithm'), ('algorithm', 'obtain'), ('across', 'range'), ('algorithm', 'behind'), ('fitness', 'function'), ('century', 'rapid'), ('driving', 'vehicle'), ('intelligence', 'placed'), ('role', 'include'), ('transform', 'twenty'), ('go', 'review'), ('function', 'play'), ('form', 'artificial'), ('learning', 'highlight'), ('important', 'role'), ('dataset', 'increase'), ('rapid', 'recent'), ('computer', 'competence'), ('dimension', 'dataset'), ('selection', 'f'), ('placed', 'transform'), ('optimal', 'subset'), ('redundant', 'feature'), ('recent', 'progress'), ('machine', 'learning'), ('best', 'solution'), ('complex', 'board'), ('growth', 'size'), ('obtain', 'best'), ('function', 'orient'), ('architecture', 'algorithm'), ('board', 'game'), ('specific', 'approach'), ('proper', 'fitness'), ('medicine', 'fitness'), ('problem', 'reduces'), ('optimisation', 'problem'), ('fundamental', 'algorithm'), ('performance', 'complex'), ('vehicle', 'language'), ('f', 'optimisation'), ('competence', 'across'), ('increasing', 'computer'), ('learning', 'ml'), ('game', 'go'), ('choosing', 'proper'), ('learning', 'optimisation'), ('algorithm', 'classification'), ('size', 'datasets'), ('beyond', 'human'), ('translation', 'chatbots'), ('increase', 'performance'), ('artificial', 'intelligence'), ('feature', 'selection'), ('searching', 'strategy'), ('selection', 'optimal'), ('feature', 'elimination'), ('optimisation', 'summarise')}\n",
      "Tipo de plagio: Reordenamiento de frases\n",
      "Coincidencias para el plagio:\n",
      "----------------------------\n",
      "Cadena original: (Longitud: 569)\n",
      "Cadena plagiada:  (Longitud: 785)\n",
      "\n",
      "Titulo: FID-10.txt\n",
      "Similitud entre 'FID-10.txt' y 'org-007.txt': 86.77%\n",
      "ngrams originales:  {('review', 'conducted'), ('network', 'teaching'), ('personalized', 'learning'), ('education', 'number'), ('academic', 'community'), ('discus', 'challenge'), ('language', 'processing'), ('educational', 'robot'), ('topic', 'related'), ('also', 'discus'), ('include', 'intelligent'), ('various', 'aspect'), ('use', 'artificial'), ('based', '4'), ('recommender', 'system'), ('reveal', 'increasing'), ('4', '519'), ('attempt', 'fill'), ('data', 'mining'), ('large', 'scale'), ('comprehensively', 'investigate'), ('special', 'education'), ('education', 'aied'), ('mining', 'performance'), ('tutoring', 'system'), ('natural', 'language'), ('publication', '2000'), ('research', 'topic'), ('identify', 'trend'), ('scale', 'review'), ('trend', 'topic'), ('collaborative', 'learning'), ('educational', 'data'), ('investigate', 'various'), ('interest', 'using'), ('increased', 'however'), ('robot', 'ai'), ('2019', 'attempt'), ('future', 'direction'), ('emotion', 'detection'), ('challenge', 'future'), ('increasing', 'use'), ('evaluation', 'affective'), ('education', 'educational'), ('teaching', 'evaluation'), ('topic', 'include'), ('field', 'increased'), ('ai', 'technology'), ('field', 'based'), ('processing', 'language'), ('learner', 'emotion'), ('published', 'study'), ('learning', 'neural'), ('technology', 'education'), ('neural', 'network'), ('affective', 'computing'), ('2000', '2019'), ('review', 'reveal'), ('using', 'topicbased'), ('direction', 'aied'), ('detection', 'recommender'), ('topicbased', 'bibliometrics'), ('gap', 'identify'), ('computing', 'learner'), ('intelligent', 'tutoring'), ('learning', 'also'), ('ai', 'educational'), ('however', 'large'), ('education', 'natural'), ('educational', 'purpose'), ('result', 'review'), ('fill', 'gap'), ('related', 'ai'), ('supported', 'collaborative'), ('system', 'personalized'), ('performance', 'prediction'), ('conducted', 'comprehensively'), ('increasing', 'interest'), ('analysis', 'computer'), ('ai', 'application'), ('number', 'published'), ('community', 'main'), ('computer', 'supported'), ('language', 'education'), ('using', 'ai'), ('aspect', 'field'), ('bibliometrics', 'result'), ('purpose', 'academic'), ('519', 'publication'), ('discourse', 'analysis'), ('intelligence', 'ai'), ('artificial', 'intelligence'), ('application', 'education'), ('study', 'field'), ('main', 'research'), ('system', 'special'), ('prediction', 'discourse'), ('ai', 'education'), ('aied', 'using')}\n",
      "ngrams plagio:  {('network', 'teaching'), ('personalized', 'learning'), ('academic', 'community'), ('language', 'processing'), ('educational', 'robot'), ('topic', 'related'), ('include', 'intelligent'), ('address', 'challenge'), ('recommender', 'system'), ('4', '519'), ('2019', 'using'), ('data', 'mining'), ('large', 'scale'), ('aim', 'bridge'), ('special', 'education'), ('education', 'aied'), ('mining', 'performance'), ('tutoring', 'system'), ('natural', 'language'), ('publication', '2000'), ('research', 'topic'), ('leading', 'rise'), ('identify', 'trend'), ('scale', 'review'), ('trend', 'topic'), ('collaborative', 'learning'), ('educational', 'data'), ('interest', 'using'), ('within', 'academic'), ('robot', 'ai'), ('future', 'direction'), ('emotion', 'detection'), ('topic', 'based'), ('gap', 'analyzing'), ('challenge', 'future'), ('evaluation', 'affective'), ('despite', 'comprehensive'), ('education', 'educational'), ('teaching', 'evaluation'), ('topic', 'include'), ('using', 'topic'), ('result', 'indicate'), ('field', 'lacking'), ('ai', 'technology'), ('processing', 'language'), ('learner', 'emotion'), ('published', 'study'), ('learning', 'neural'), ('technology', 'education'), ('neural', 'network'), ('primary', 'research'), ('affective', 'computing'), ('study', 'aim'), ('2000', '2019'), ('bibliometrics', 'identify'), ('direction', 'aied'), ('utilization', 'artificial'), ('detection', 'recommender'), ('computing', 'learner'), ('purpose', 'within'), ('intelligent', 'tutoring'), ('analyzing', '4'), ('education', 'surged'), ('ai', 'educational'), ('learning', 'study'), ('lacking', 'study'), ('based', 'bibliometrics'), ('also', 'address'), ('education', 'natural'), ('review', 'field'), ('educational', 'purpose'), ('study', 'also'), ('supported', 'collaborative'), ('related', 'ai'), ('system', 'personalized'), ('performance', 'prediction'), ('surged', 'leading'), ('comprehensive', 'large'), ('analysis', 'computer'), ('rise', 'published'), ('study', 'despite'), ('ai', 'application'), ('indicate', 'growing'), ('computer', 'supported'), ('language', 'education'), ('using', 'ai'), ('aied', 'result'), ('519', 'publication'), ('discourse', 'analysis'), ('bridge', 'gap'), ('intelligence', 'ai'), ('artificial', 'intelligence'), ('application', 'education'), ('growing', 'interest'), ('community', 'primary'), ('system', 'special'), ('prediction', 'discourse'), ('ai', 'education')}\n",
      "Tipo de plagio: Inserción de frases\n",
      "Coincidencias para el plagio:\n",
      "----------------------------\n",
      "Cadena original: (Longitud: 843)\n",
      "Cadena plagiada:  (Longitud: 824)\n",
      "\n",
      "Titulo: FID-01.txt\n",
      "Similitud entre 'FID-01.txt' y 'org-076.txt': 77.38%\n",
      "ngrams originales:  {('impediment', 'effectively'), ('desired', 'trajectory'), ('strategy', 'nonholonomic'), ('failure', 'robot'), ('technology', 'propose'), ('unknown', 'nonlinear'), ('number', 'controller'), ('compensate', 'effect'), ('fault', 'using'), ('fuzzy', 'event'), ('resource', 'yet'), ('control', 'nonholonomic'), ('fewer', 'network'), ('strategy', 'guarantee'), ('engage', 'leader'), ('maintenance', 'ever'), ('present', 'due'), ('adaptive', 'method'), ('range', 'impediment'), ('triggered', 'formation'), ('general', 'barrier'), ('reduce', 'number'), ('introduce', 'general'), ('uninterrupted', 'tracking'), ('method', 'approximate'), ('event', 'triggered'), ('dynamic', 'surface'), ('performance', 'methodology'), ('due', 'limitation'), ('characterized', 'infinite'), ('collision', 'avoidance'), ('execution', 'compensate'), ('event', 'triggering'), ('generated', 'leader'), ('controller', 'execution'), ('communication', 'resource'), ('distance', 'visual'), ('constrained', 'range'), ('decentralized', 'adaptive'), ('effectively', 'furthermore'), ('adaptive', 'fuzzy'), ('actuator', 'fault'), ('field', 'regard'), ('approximate', 'unknown'), ('uncertain', 'parameter'), ('surface', 'technology'), ('function', 'prescribed'), ('intricacy', 'adaptive'), ('information', 'exploration'), ('actuator', 'failure'), ('network', 'communication'), ('ultimately', 'bounded'), ('leader', 'aid'), ('system', 'fl'), ('aid', 'dynamic'), ('etft', 'control'), ('methodology', 'tackle'), ('robot', 'engage'), ('dynamic', 'course'), ('barrier', 'function'), ('function', 'uncertain'), ('sguub', 'ultimately'), ('maintain', 'uninterrupted'), ('avoidance', 'connectivity'), ('nonlinear', 'function'), ('logic', 'system'), ('course', 'information'), ('fuzzy', 'logic'), ('yet', 'maintain'), ('arising', 'infinite'), ('propose', 'decentralized'), ('using', 'fewer'), ('signal', 'semi'), ('employ', 'adaptive'), ('system', 'characterized'), ('visual', 'field'), ('uniformly', 'ultimately'), ('parameter', 'present'), ('nonholonomic', 'multirobot'), ('fault', 'tolerant'), ('ever', 'present'), ('ï', 'article'), ('semi', 'global'), ('article', 'delf'), ('present', 'robotic'), ('demonstrate', 'practical'), ('multirobot', 'system'), ('ultimately', 'demonstrate'), ('effect', 'arising'), ('etft', 'formation'), ('limitation', 'distance'), ('adaptive', 'event'), ('feasibility', 'etft'), ('fault', 'range'), ('trajectory', 'generated'), ('prescribed', 'performance'), ('range', 'constraint'), ('global', 'uniformly'), ('address', 'issue'), ('exploration', 'problem'), ('robotic', 'dynamic'), ('regard', 'introduce'), ('control', 'strategy'), ('practical', 'feasibility'), ('triggering', 'fault'), ('tackle', 'constrained'), ('infinite', 'actuator'), ('connectivity', 'maintenance'), ('moment', 'actuator'), ('tolerant', 'etft'), ('furthermore', 'reduce'), ('formation', 'tracking'), ('problem', 'collision'), ('formation', 'control'), ('guarantee', 'signal'), ('fl', 'employ'), ('bounded', 'sguub'), ('constraint', 'address'), ('issue', 'leverage'), ('tracking', 'desired'), ('leader', 'moment'), ('power', 'fuzzy'), ('leverage', 'power'), ('delf', 'intricacy'), ('tracking', 'control')}\n",
      "ngrams plagio:  {('recall', 'rate'), ('desired', 'trajectory'), ('detection', 'method'), ('strategy', 'nonholonomic'), ('failure', 'robot'), ('difficult', 'distinguish'), ('unknown', 'nonlinear'), ('number', 'controller'), ('compensate', 'effect'), ('method', 'significantly'), ('fault', 'using'), ('fuzzy', 'event'), ('resource', 'yet'), ('control', 'nonholonomic'), ('fewer', 'network'), ('engage', 'leader'), ('higher', 'method'), ('maintenance', 'ever'), ('present', 'due'), ('adaptive', 'method'), ('point', 'test'), ('disadvantage', 'difficult'), ('mastery', 'certain'), ('significantly', 'higher'), ('triggered', 'formation'), ('traditional', 'cheating'), ('reduce', 'number'), ('uninterrupted', 'tracking'), ('constraint', 'traditional'), ('measure', 'studentsâ'), ('method', 'approximate'), ('event', 'triggered'), ('leader', 'guarantee'), ('difficult', 'detect'), ('false', 'rate'), ('cheating', 'difficult'), ('due', 'limitation'), ('field', 'paper'), ('characterized', 'infinite'), ('collision', 'avoidance'), ('execution', 'compensate'), ('based', 'person'), ('certain', 'knowledge'), ('plagiarist', 'victim'), ('person', 'fit'), ('generated', 'leader'), ('studentsâ', 'mastery'), ('test', 'method'), ('controller', 'execution'), ('communication', 'resource'), ('plagiarist', 'plagiarist'), ('distance', 'visual'), ('victim', 'plagiarism'), ('adaptive', 'fuzzy'), ('actuator', 'fault'), ('approximate', 'unknown'), ('uncertain', 'parameter'), ('intricacy', 'adaptive'), ('method', 'many'), ('information', 'exploration'), ('actuator', 'failure'), ('network', 'communication'), ('ultimately', 'bounded'), ('based', 'improved'), ('plagiarist', 'difficult'), ('system', 'fl'), ('concept', 'knowledge'), ('etft', 'control'), ('point', 'mastery'), ('robot', 'engage'), ('dynamic', 'course'), ('introduced', 'measure'), ('method', 'based'), ('model', 'proposed'), ('coincidence', 'address'), ('function', 'uncertain'), ('sguub', 'ultimately'), ('system', 'experiment'), ('improved', 'cognitive'), ('maintain', 'uninterrupted'), ('avoidance', 'connectivity'), ('cheating', 'multi'), ('source', 'cheating'), ('nonlinear', 'function'), ('logic', 'system'), ('course', 'information'), ('fuzzy', 'logic'), ('yet', 'maintain'), ('arising', 'infinite'), ('rate', 'right'), ('cheating', 'detection'), ('using', 'fewer'), ('signal', 'semi'), ('covert', 'equipment'), ('employ', 'adaptive'), ('system', 'characterized'), ('visual', 'field'), ('uniformly', 'ultimately'), ('index', 'introduced'), ('parameter', 'present'), ('nonholonomic', 'multirobot'), ('rate', 'method'), ('ever', 'present'), ('ï', 'article'), ('show', 'precision'), ('paper', 'concept'), ('semi', 'global'), ('article', 'delf'), ('plagiarism', 'coincidence'), ('right', 'rate'), ('present', 'robotic'), ('demonstrate', 'practical'), ('cognitive', 'diagnostic'), ('multi', 'source'), ('multirobot', 'system'), ('ultimately', 'demonstrate'), ('effect', 'arising'), ('limitation', 'distance'), ('cheating', 'based'), ('feasibility', 'etft'), ('fault', 'range'), ('trajectory', 'generated'), ('distinguish', 'plagiarist'), ('many', 'disadvantage'), ('range', 'constraint'), ('diagnostic', 'model'), ('knowledge', 'point'), ('address', 'issue'), ('global', 'uniformly'), ('exploration', 'problem'), ('robotic', 'dynamic'), ('practical', 'feasibility'), ('control', 'strategy'), ('mastery', 'index'), ('detect', 'covert'), ('method', 'cheating'), ('proposed', 'furthermore'), ('infinite', 'actuator'), ('connectivity', 'maintenance'), ('moment', 'actuator'), ('furthermore', 'reduce'), ('fit', 'index'), ('equipment', 'cheating'), ('formation', 'tracking'), ('problem', 'collision'), ('guarantee', 'signal'), ('fl', 'employ'), ('precision', 'recall'), ('experiment', 'show'), ('bounded', 'sguub'), ('issue', 'leverage'), ('tracking', 'desired'), ('leader', 'moment'), ('power', 'fuzzy'), ('leverage', 'power'), ('delf', 'intricacy'), ('based', 'false'), ('tracking', 'control')}\n",
      "Tipo de plagio: Reordenamiento de frases\n",
      "Coincidencias para el plagio:\n",
      "----------------------------\n",
      "Cadena original: (Longitud: 1128)\n",
      "Cadena plagiada:  (Longitud: 1437)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sergiogonzalez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 437
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
